{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from together import Together\n",
    "import openai\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######   EXP. 1: GPT-3.5-turbo corpus   #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kids with age from books.csv\n",
    "openai.api_key = \"api_key\"  \n",
    "\n",
    "output_directory = '/Users/hannawoloszyn/Desktop/GPT_kids/gpt_summaries_kids'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def read_titles_and_ages(csv_filename):\n",
    "    entries = []\n",
    "    with open(csv_filename, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            title = row.get('Titel', '').strip()\n",
    "            age = row.get('Lesealter.Amazon', '').strip()\n",
    "            if title:\n",
    "                entries.append((title, age))\n",
    "    return entries\n",
    "\n",
    "def prompt_generator(titel, age=None, other=False):\n",
    "    if other:\n",
    "        return [{\"role\": \"system\", \"content\": str(titel)}]\n",
    "\n",
    "    if not age or str(age).strip().lower() in ['na', '']:\n",
    "        content = f\"4000 Wörter zu '{titel}' auf Deutsch für Kinder\"\n",
    "    else:\n",
    "        content = f\"4000 Wörter zu '{titel}' auf Deutsch geschrieben für Kinder im Alter {age}\"\n",
    "\n",
    "    return [{\"role\": \"system\", \"content\": content}]\n",
    "\n",
    "def get_gpt_text(prompt, model=\"gpt-3.5-turbo\", n=10):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=4000,\n",
    "        n=n,\n",
    "        stop=None,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return '\\n\\n---\\n\\n'.join([choice['message']['content'] for choice in response['choices']])\n",
    "\n",
    "def write_file(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def generate_summaries_and_save_files(entries, start_index=0):\n",
    "    for index, (title, age) in enumerate(entries, start=start_index):\n",
    "        prompt = prompt_generator(title, age)\n",
    "        summaries = get_gpt_text(prompt)\n",
    "        age_suffix = age if age and age.lower() != 'na' else 'general'\n",
    "        file_path = os.path.join(output_directory, f\"summary_kids_{age_suffix}_{index}.txt\")\n",
    "        write_file(file_path, summaries)\n",
    "        print(f\"Saved summaries for '{title}' (age: {age}) to '{file_path}'\")\n",
    "\n",
    "csv_filename = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "entries = read_titles_and_ages(csv_filename)\n",
    "generate_summaries_and_save_files(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######   EXP. 2: GPT-3.5-turbo corpus   #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kids with age restriction\n",
    "openai.api_key = \"api_key\"\n",
    "\n",
    "output_directory = '/Users/hannawoloszyn/Desktop/GPT_kids/gpt_summaries_age_4'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "age = 4\n",
    "\n",
    "def read_book_titles(csv_filename):\n",
    "    titles = []\n",
    "    with open(csv_filename, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            titles.append(row['Titel'])\n",
    "    return titles\n",
    "\n",
    "def prompt_generator(title):\n",
    "    return [{\"role\": \"user\", \"content\": f\"4000 Wörter zu '{title}' auf Deutsch geschrieben für Kinder im Alter {age}\"}]\n",
    "\n",
    "def get_gpt_text(prompt, model=\"gpt-3.5-turbo\", n=10):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=4000,\n",
    "        n=n,\n",
    "        stop=None,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return '\\n\\n---\\n\\n'.join([choice['message']['content'] for choice in response['choices']])\n",
    "\n",
    "def write_file(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def generate_summaries_and_save_files(titles, start_index=0):\n",
    "    for index, title in enumerate(titles, start=start_index):\n",
    "        prompt = prompt_generator(title)\n",
    "        summaries = get_gpt_text(prompt)\n",
    "        file_path = os.path.join(output_directory, f\"summary_age_{age}_{index}.txt\")\n",
    "        write_file(file_path, summaries)\n",
    "        print(f\"Saved summaries for '{title}' to '{file_path}'\")\n",
    "\n",
    "csv_filename = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "titles = read_book_titles(csv_filename)\n",
    "generate_summaries_and_save_files(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kids without age restriction\n",
    "openai.api_key = \"api_key\"  \n",
    "\n",
    "output_directory = '/Users/hannawoloszyn/Desktop/GPT_kids/gpt_summaries_adults'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def read_book_titles(csv_filename):\n",
    "    titles = []\n",
    "    with open(csv_filename, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            titles.append(row['Titel'])\n",
    "    return titles\n",
    "\n",
    "def prompt_generator(title):\n",
    "    return [{\"role\": \"user\", \"content\": f\"4000 Wörter zu '{title}' auf Deutsch geschrieben für Kinder\"}]\n",
    "\n",
    "def get_gpt_text(prompt, model=\"gpt-3.5-turbo\", n=10):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=4000,\n",
    "        n=n,\n",
    "        stop=None,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return '\\n\\n---\\n\\n'.join([choice['message']['content'] for choice in response['choices']])\n",
    "\n",
    "def write_file(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def generate_summaries_and_save_files(titles, start_index=0):\n",
    "    for index, title in enumerate(titles, start=start_index):\n",
    "        prompt = prompt_generator(title)\n",
    "        summaries = get_gpt_text(prompt)\n",
    "        file_path = os.path.join(output_directory, f\"summary_adults_{index}.txt\")\n",
    "        write_file(file_path, summaries)\n",
    "        print(f\"Saved summaries for '{title}' to '{file_path}'\")\n",
    "\n",
    "csv_filename = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "titles = read_book_titles(csv_filename)\n",
    "generate_summaries_and_save_files(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adults\n",
    "openai.api_key = \"api_key\"  \n",
    "\n",
    "output_directory = '/Users/hannawoloszyn/Desktop/GPT_kids/gpt_summaries_adults'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def read_book_titles(csv_filename):\n",
    "    titles = []\n",
    "    with open(csv_filename, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            titles.append(row['Titel'])\n",
    "    return titles\n",
    "\n",
    "def prompt_generator(title):\n",
    "    return [{\"role\": \"user\", \"content\": f\"4000 Wörter zu '{title}' auf Deutsch geschrieben für Erwachsene\"}]\n",
    "\n",
    "def get_gpt_text(prompt, model=\"gpt-3.5-turbo\", n=10):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=4000,\n",
    "        n=n,\n",
    "        stop=None,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return '\\n\\n---\\n\\n'.join([choice['message']['content'] for choice in response['choices']])\n",
    "\n",
    "def write_file(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def generate_summaries_and_save_files(titles, start_index=0):\n",
    "    for index, title in enumerate(titles, start=start_index):\n",
    "        prompt = prompt_generator(title)\n",
    "        summaries = get_gpt_text(prompt)\n",
    "        file_path = os.path.join(output_directory, f\"summary_adults_{index}.txt\")\n",
    "        write_file(file_path, summaries)\n",
    "        print(f\"Saved summaries for '{title}' to '{file_path}'\")\n",
    "\n",
    "csv_filename = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "titles = read_book_titles(csv_filename)\n",
    "generate_summaries_and_save_files(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######   EXP. 3: llama corpora   #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short llama corpus\n",
    "\n",
    "def generate_short_text(prompt, \n",
    "                        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\", \n",
    "                        max_tokens=700):\n",
    "    client = Together(api_key=\"api_key\")\n",
    "    \n",
    "    text = \"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    for token in response:\n",
    "        if hasattr(token, 'choices'):\n",
    "            text += token.choices[0].delta.content\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def count_words(filepath):\n",
    "    with open(filepath, 'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "        words = data.split()\n",
    "        print(f'Number of words in {filepath}:', len(words))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "    books_df = pd.read_csv(csv_path, sep=\";\", engine=\"python\")\n",
    "    \n",
    "    start_index = 0\n",
    "    \n",
    "    for index, row in books_df.iloc[start_index:].iterrows():\n",
    "        book_title = row[\"Titel\"]\n",
    "        age = row[\"Lesealter.Amazon\"]\n",
    "        prompt = f\"Schreibe eine Kindergeschichte (300 Wörter) für Kinder im Alter {age} über: {book_title}\\n\\n\"\n",
    "        \n",
    "        output_path = f\"/Users/hannawoloszyn/Desktop/GPT_kids/llama_corpus/llama_short_corpus/short_response_{index+1}.txt\"\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for i in range(10):\n",
    "                short_text = generate_short_text(prompt)\n",
    "                f.write(short_text + \"\\n\\n\")\n",
    "                print(f\"Generated story {i+1} for book: {book_title}\")\n",
    "        \n",
    "        print(f\"Text generation complete. All 10 stories saved to {output_path}\")\n",
    "\n",
    "        count_words(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long llama corpus\n",
    "\n",
    "def generate_long_text(prompt, \n",
    "                       model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\", \n",
    "                       chunk_size=1000, \n",
    "                       total_words=4000):\n",
    "    client = Together(api_key=\"api_key\")\n",
    "    \n",
    "    text = \"\"\n",
    "    current_prompt = prompt\n",
    "    words_generated = 0\n",
    "    \n",
    "    while words_generated < total_words:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": current_prompt}],\n",
    "            max_tokens=chunk_size * 2,\n",
    "            temperature=0.7,\n",
    "            top_p=0.7,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1,\n",
    "            stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        new_content = \"\"\n",
    "        for token in response:\n",
    "            if hasattr(token, 'choices'):\n",
    "                new_content += token.choices[0].delta.content\n",
    "        \n",
    "        text += \" \" + new_content.strip()\n",
    "        words_generated = len(text.split())\n",
    "        \n",
    "        current_prompt = \"Continue from: \" + text[-500:]\n",
    "        \n",
    "        print(f\"Words generated: {words_generated}\") \n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "    books_df = pd.read_csv(csv_path, sep=\";\", engine=\"python\")\n",
    "    \n",
    "    start_index = 0\n",
    "    \n",
    "    for index, row in books_df.iloc[start_index:].iterrows():\n",
    "        book_title = row[\"Titel\"]\n",
    "        age = row[\"Lesealter.Amazon\"]\n",
    "        prompt = f\"Schreibe eine lange Kindergeschichte (4000 Wörter) für Kinder im Alter {age} über: {book_title}\\n\\n\"\n",
    "        \n",
    "        long_text = generate_long_text(prompt)\n",
    "        \n",
    "        output_path = f\"/Users/hannawoloszyn/Desktop/GPT_kids/llama_texts/5th_long_response_{index+1}.txt\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(long_text)\n",
    "        \n",
    "        print(f\"Text generation complete. Saved to {output_path}\")\n",
    "\n",
    "        count_words(output_path)\n",
    "\n",
    "def count_words(filepath):\n",
    "    with open(filepath, 'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "        words = data.split()\n",
    "        print(f'Number of words in {filepath}:', len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######   EXP. 3: DeepSeek corpora   #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short DeepSeek corpus\n",
    "\n",
    "def generate_short_text(prompt, \n",
    "                        model=\"deepseek-ai/DeepSeek-V3\", \n",
    "                        max_tokens=600):\n",
    "    client = Together(api_key=\"api_key\")\n",
    "    \n",
    "    text = \"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    for token in response:\n",
    "        if hasattr(token, 'choices'):\n",
    "            text += token.choices[0].delta.content\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "    books_df = pd.read_csv(csv_path, sep=\";\", engine=\"python\")\n",
    "    \n",
    "    start_index = 0\n",
    "\n",
    "    for index, row in books_df.iloc[start_index:].iterrows():\n",
    "        book_title = row[\"Titel\"]\n",
    "        age = row[\"Lesealter.Amazon\"]\n",
    "        \n",
    "        prompt = f\"Schreibe eine Kindergeschichte für Kinder im Alter {age} über: {book_title}\\n\\n\"\n",
    "        \n",
    "        combined_text = \"\"\n",
    "        for _ in range(10):  #10 stories in one file\n",
    "            short_text = generate_short_text(prompt)\n",
    "            combined_text += short_text + \"\\n\\n\"\n",
    "        \n",
    "        output_path = f\"/Users/hannawoloszyn/Desktop/GPT_kids/deepseek_corpus/short_corpus/4th_short_response_{index+1}.txt\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(combined_text)\n",
    "        \n",
    "        print(f\"Text generation complete. Saved to {output_path}\")\n",
    "\n",
    "        count_words(output_path)\n",
    "\n",
    "def count_words(filepath):\n",
    "    with open(filepath, 'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "        words = data.split()\n",
    "        print(f'Number of words in {filepath}:', len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long DeepSeek corpus\n",
    "\n",
    "def generate_long_text(prompt, \n",
    "                       model=\"deepseek-ai/DeepSeek-V3\", \n",
    "                       chunk_size=1000, \n",
    "                       total_words=4000):\n",
    "    client = Together(api_key=\"api_key\")\n",
    "    \n",
    "    text = \"\"\n",
    "    current_prompt = prompt\n",
    "    words_generated = 0\n",
    "    \n",
    "    while words_generated < total_words:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                      {\"role\": \"user\", \"content\": current_prompt}],\n",
    "            max_tokens=chunk_size * 2,\n",
    "            temperature=0.7,\n",
    "            top_p=0.7,\n",
    "            repetition_penalty=1.0,\n",
    "            stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        new_content = \"\"\n",
    "        for token in response:\n",
    "            if hasattr(token, 'choices'):\n",
    "                new_content += token.choices[0].delta.content\n",
    "        \n",
    "        text += \" \" + new_content.strip()\n",
    "        words_generated = len(text.split())\n",
    "        \n",
    "        current_prompt = \"Continue from: \" + text[-500:]\n",
    "        \n",
    "        print(f\"Words generated: {words_generated}\")\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def count_words(filepath):\n",
    "    with open(filepath, 'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "        words = data.split()\n",
    "        print(f'Number of words in {filepath}:', len(words))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/Users/hannawoloszyn/Desktop/GPT_kids/stimuli/books.csv\"\n",
    "    books_df = pd.read_csv(csv_path, sep=\";\", engine=\"python\")\n",
    "    \n",
    "    start_index = 0\n",
    "\n",
    "    for index, row in books_df.iloc[start_index:].iterrows():\n",
    "        book_title = row[\"Titel\"]\n",
    "        age = row[\"Lesealter.Amazon\"]\n",
    "        prompt = f\"Schreibe eine lange Kindergeschichte (4000 Wörter) für Kinder im Alter {age} über: {book_title}\\n\\n\"\n",
    "        \n",
    "        long_text = generate_long_text(prompt)\n",
    "        \n",
    "        output_path = f\"/Users/hannawoloszyn/Desktop/GPT_kids/deepseek_corpus/long_corpus/long_response_{index+1}.txt\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(long_text)\n",
    "        \n",
    "        print(f\"Text generation complete. Saved to {output_path}\")\n",
    "        count_words(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
