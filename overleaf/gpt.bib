
@book{kuhn_tidy_nodate,
	title = {Tidy {Modeling} with {R}},
	url = {https://www.tmwr.org/},
	abstract = {The tidymodels framework is a collection of R packages for modeling and machine learning using tidyverse principles. This book provides a thorough introduction to how to use tidymodels, and an outline of good methodology and statistical practice for phases of the modeling process.},
	urldate = {2023-05-22},
	author = {Kuhn, Max and Silge, Julia},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\JME4THKM\\www.tmwr.org.html:text/html},
}

@book{silge_chapter_nodate,
	title = {Chapter 2 {Tokenization} {\textbar} {Supervised} {Machine} {Learning} for {Text} {Analysis} in {R}},
	url = {https://smltar.com/tokenization.html},
	abstract = {Chapter 2 Tokenization {\textbar} Supervised Machine Learning for Text Analysis in R},
	urldate = {2023-05-22},
	author = {Silge, Emil Hvitfeldt {and} Julia},
}

@book{hvitfeldt_supervised_2021,
	title = {Supervised machine learning for text analysis in {R}},
	publisher = {CRC Press},
	author = {Hvitfeldt, Emil and Silge, Julia},
	year = {2021},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\L3TDCN9Z\\books.html:text/html},
}

@misc{lebryk_introduction_2021,
	title = {Introduction to the {Structural} {Topic} {Model} ({STM})},
	url = {https://towardsdatascience.com/introduction-to-the-structural-topic-model-stm-34ec4bd5383},
	abstract = {A unique way to use topic modelling for social science research},
	language = {en},
	urldate = {2023-05-22},
	journal = {Medium},
	author = {Lebryk, Theo},
	month = apr,
	year = {2021},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\NWXYIW9A\\introduction-to-the-structural-topic-model-stm-34ec4bd5383.html:text/html},
}

@book{grimmer_text_2022,
	title = {Text as data: {A} new framework for machine learning and the social sciences},
	shorttitle = {Text as data},
	publisher = {Princeton University Press},
	author = {Grimmer, Justin and Roberts, Margaret E. and Stewart, Brandon M.},
	year = {2022},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\AP8UUV29\\books.html:text/html},
}

@book{silge_text_2017,
	title = {Text mining with {R}: {A} tidy approach},
	shorttitle = {Text mining with {R}},
	publisher = {" O'Reilly Media, Inc."},
	author = {Silge, Julia and Robinson, David},
	year = {2017},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\NF3RUNRZ\\books.html:text/html},
}

@article{gregorova_access_2023,
	title = {Access to meaning from visual input: {Object} and word frequency effects in categorization behavior.},
	shorttitle = {Access to meaning from visual input},
	journal = {Journal of Experimental Psychology: General},
	author = {Gregorova, Klara and Turini, Jacopo and Gagl, Benjamin and Võ, Melissa Le-Hoa},
	year = {2023},
	note = {Publisher: American Psychological Association},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\L6XDK6TC\\2023-69316-001.html:text/html},
}

@article{keuleers_subtlex-nl_2010,
	title = {{SUBTLEX}-{NL}: {A} new measure for {Dutch} word frequency based on film subtitles},
	volume = {42},
	shorttitle = {{SUBTLEX}-{NL}},
	number = {3},
	journal = {Behavior Research Methods},
	author = {Keuleers, EMMANUEL and Brysbaert, MARC and New, BORIS},
	year = {2010},
	pages = {643--650},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\4SX3BSQF\\KEULEERS et al. - 2010 - SUBTLEX-NL A new measure for Dutch word frequency.pdf:application/pdf},
}

@article{slobin_origins_1997,
	title = {The origins of grammaticizable notions: {Beyond} the individual mind},
	volume = {5},
	shorttitle = {The origins of grammaticizable notions},
	journal = {The crosslinguistic study of language acquisition. Expanding the contexts},
	author = {Slobin, Dan I.},
	year = {1997},
	note = {Publisher: Lawrence Erlbaum Associates},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\EYI3GBWN\\1573387449547652480.html:text/html},
}

@article{slobin_learning_1991,
	title = {Learning to think for speaking: {Native} language, cognition, and rhetorical style},
	volume = {1},
	shorttitle = {Learning to think for speaking},
	number = {1},
	journal = {Pragmatics. Quarterly Publication of the International Pragmatics Association (IPrA)},
	author = {Slobin, Dan I.},
	year = {1991},
	note = {Publisher: John Benjamins Publishing Company Amsterdam/Philadephia},
	pages = {7--25},
}

@article{slobin_learning_nodate,
	title = {{LEARNING} {TO} {THINK} {FOR} {SPEAKING}: {NATTVE} {LANGUAGE}, {COGNITION}, {AND} {RHETORICAL} {STYLB}},
	shorttitle = {{LEARNING} {TO} {THINK} {FOR} {SPEAKING}},
	author = {Slobin, Dan I.},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\DRSN8772\\Slobin - LEARNING TO THINK FOR SPEAKING NATTVE LANGUAGE, C.pdf:application/pdf},
}

@article{brown_language_2020,
	title = {Language models are few-shot learners},
	volume = {33},
	journal = {Advances in neural information processing systems},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D. and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda},
	year = {2020},
	pages = {1877--1901},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\ZHWNW425\\1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html:text/html},
}

@book{hart_meaningful_1995,
	title = {Meaningful differences in the everyday experience of young {American} children.},
	publisher = {Paul H Brookes Publishing},
	author = {Hart, Betty and Risley, Todd R.},
	year = {1995},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\WNP6XKWK\\1995-98021-000.html:text/html},
}

@article{stokes_neighborhood_2010,
	title = {Neighborhood {Density} and {Word} {Frequency} {Predict} {Vocabulary} {Size} in {Toddlers}},
	volume = {53},
	issn = {1092-4388, 1558-9102},
	url = {http://pubs.asha.org/doi/10.1044/1092-4388%282009/08-0254%29},
	doi = {10.1044/1092-4388(2009/08-0254)},
	abstract = {Purpose
              To document the lexical characteristics of neighborhood density (ND) and word frequency (WF) in the lexicons of a large sample of English-speaking toddlers.
            
            
              Method
              
                Parents of 222 British-English–speaking children aged 27(±3) months completed a British adaptation of the MacArthur–Bates Communicative Development Inventory: Words and Sentences (MCDI; Klee \& Harrison, 2001). Child words were coded for ND and WF, and the relationships among vocabulary, ND, and WF were examined. A cut-point of −1
                SD
                below the mean on the MCDI classified children into one of two groups: low or high vocabulary size. Group differences on ND and WF were examined using nonparametric statistics.
              
            
            
              Results
              In a hierarchical regression, ND and WF accounted for 47\% and 14\% of unique variance in MCDI scores, respectively. Low-vocabulary children scored significantly higher on ND and significantly lower on WF than did high-vocabulary children, but there was more variability in ND and WF for children at the lowest points of the vocabulary continuum.
            
            
              Conclusion
              Children at the lowest points of a continuum of vocabulary size may be extracting statistical properties of the input language in a manner quite different from their more able age peers.},
	language = {en},
	number = {3},
	urldate = {2023-05-16},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Stokes, Stephanie F.},
	month = jun,
	year = {2010},
	pages = {670--683},
}

@article{brysbaert_impact_2016,
	title = {The impact of word prevalence on lexical decision times: {Evidence} from the {Dutch} {Lexicon} {Project} 2.},
	volume = {42},
	issn = {1939-1277, 0096-1523},
	shorttitle = {The impact of word prevalence on lexical decision times},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xhp0000159},
	doi = {10.1037/xhp0000159},
	abstract = {Keuleers, Stevens, Mandera, and Brysbaert (2015) presented a new variable, word prevalence, defined as word knowledge in the population. Some words are known to more people than other. This is particularly true for low-frequency words (e.g., screenshot vs. scourage). In the present study, we examined the impact of the measure by collecting lexical decision times for 30,000 Dutch word lemmas of various lengths (the Dutch Lexicon Project 2). Word prevalence had the second highest correlation with lexical decision times (after word frequency): Words known by everyone in the population were responded to 100 ms faster than words known to only half of the population, even after controlling for word frequency, word length, age of acquisition, similarity to other words, and concreteness. Because word prevalence has rather low correlations with the existing measures (including word frequency), the unique variance it contributes to lexical decision times is higher than that of the other variables. We consider the reasons why word prevalence has an impact on word processing times and we argue that it is likely to be the most important new variable protecting researchers against experimenter bias in selecting stimulus materials.},
	language = {en},
	number = {3},
	urldate = {2023-05-16},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Brysbaert, Marc and Stevens, Michaël and Mandera, Paweł and Keuleers, Emmanuel},
	year = {2016},
	pages = {441--458},
}

@article{hallin_effects_2018,
	title = {Effects of frequency and morphosyntactic structure on error detection, correction, and repetition in {Swedish}-speaking children},
	volume = {39},
	issn = {0142-7164, 1469-1817},
	url = {https://www.cambridge.org/core/product/identifier/S0142716418000280/type/journal_article},
	doi = {10.1017/S0142716418000280},
	abstract = {ABSTRACT
            Grammatical error detection and correction are often used to test explicit language knowledge. This study investigated effects of token frequency and error type in error detection, correction, and repetition, and performance on the three tasks were compared and related to models of metalinguistic awareness and development. Thirty Swedish-speaking 10-year-olds with typical language development participated in the study, which focused on four morphosyntactic errors: the infinitive instead of past tense for regular and irregular verbs, and the omission of the obligatory indefinite article in common and neuter gender noun phrases. Target verbs and nouns were of high or low frequency. Results showed significant effects of verb frequency in all tasks, and effects of noun gender for error detection, but not for correction and repetition. Children detected significantly more past-tense errors than they accurately corrected, but the opposite result was seen for noun phrase errors. The patterns of results both within and across tasks imply that implicit language knowledge affects performance, and that lexical frequency, even of familiar words, needs to be controlled when designing tasks for measuring grammatical knowledge. The particular challenge of the Swedish neuter noun phrase in language development and language processing needs to be further investigated.},
	language = {en},
	number = {6},
	urldate = {2023-05-16},
	journal = {Applied Psycholinguistics},
	author = {Hallin, Anna Eva and Reuterskiöld, Christina},
	month = nov,
	year = {2018},
	pages = {1189--1220},
}

@article{lieven_input_2010,
	title = {Input and first language acquisition: {Evaluating} the role of frequency},
	volume = {120},
	issn = {00243841},
	shorttitle = {Input and first language acquisition},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0024384110001658},
	doi = {10.1016/j.lingua.2010.06.005},
	abstract = {Semantic Scholar extracted view of "Input and first language acquisition: Evaluating the role of frequency" by E. Lieven},
	language = {en},
	number = {11},
	urldate = {2023-05-16},
	journal = {Lingua},
	author = {Lieven, Elena},
	month = nov,
	year = {2010},
	pages = {2546--2556},
}

@article{adelman_contextual_2006,
	title = {Contextual {Diversity}, {Not} {Word} {Frequency}, {Determines} {Word}-{Naming} and {Lexical} {Decision} {Times}},
	volume = {17},
	issn = {0956-7976, 1467-9280},
	url = {http://journals.sagepub.com/doi/10.1111/j.1467-9280.2006.01787.x},
	doi = {10.1111/j.1467-9280.2006.01787.x},
	abstract = {Word frequency is an important predictor of word-naming and lexical decision times. It is, however, confounded with contextual diversity, the number of contexts in which a word has been seen. In a study using a normative, corpus-based measure of contextual diversity, word-frequency effects were eliminated when effects of contextual diversity were taken into account (but not vice versa) across three naming and three lexical decision data sets; the same pattern of results was obtained regardless of which of three corpora was used to derive the frequency and contextual-diversity values. The results are incompatible with existing models of visual word recognition, which attribute frequency effects directly to frequency, and are particularly problematic for accounts in which frequency effects reflect learning. We argue that the results reflect the importance of likely need in memory processes, and that the continuity between reading and memory suggests using principles from memory research to inform theories of reading.},
	language = {en},
	number = {9},
	urldate = {2023-05-16},
	journal = {Psychological Science},
	author = {Adelman, James S. and Brown, Gordon D.A. and Quesada, José F.},
	month = sep,
	year = {2006},
	pages = {814--823},
	file = {Submitted Version:C\:\\Users\\jobsc\\Zotero\\storage\\ZBD6GEY4\\Adelman et al. - 2006 - Contextual Diversity, Not Word Frequency, Determin.pdf:application/pdf},
}

@article{mcdonald_rethinking_2001,
	title = {Rethinking the {Word} {Frequency} {Effect}: {The} {Neglected} {Role} of {Distributional} {Information} in {Lexical} {Processing}},
	volume = {44},
	issn = {0023-8309, 1756-6053},
	shorttitle = {Rethinking the {Word} {Frequency} {Effect}},
	url = {http://journals.sagepub.com/doi/10.1177/00238309010440030101},
	doi = {10.1177/00238309010440030101},
	abstract = {Attempts to quantify lexical variation have produced a large number of theoretical and empirical constructs, such as Word Frequency, Concreteness, and Ambiguity, which have been claimed to predict between-word differences in lexical processing behavior. Models of word recognition that have been developed to account for the effects of these variables have typically lacked adequate semantic representations, and have dealt with words as if they exist in isolation from their environment. We present a new dimension of lexical variation that is addressed to this concern. Contextual Distinctiveness(CD), a corpus-derived summary measure of the frequency distribution of the contexts in which a word occurs, is naturally compatible with contextual theories of semantic representation and meaning. Experiment 1 demonstrates that CD is a significantly better predictor of lexical decision latencies than occurrence frequency, suggesting that CD is the more psychologically relevant variable. We additionally explore the relationship between CD and six subjectively-defined measures: Concreteness, Context Availability, Number of Contexts, Ambiguity, Age of Acquisition and Familiarity and find CD to be reliably related to Ambiguity only. We argue for the priority of immediate context in determining the representation and processing of language.},
	language = {en},
	number = {3},
	urldate = {2023-05-16},
	journal = {Language and Speech},
	author = {McDonald, Scott A. and Shillcock, Richard C.},
	month = sep,
	year = {2001},
	pages = {295--322},
}

@article{hofmann_individual_2020,
	title = {Individual corpora predict fast memory retrieval during reading},
	url = {https://www.semanticscholar.org/paper/Individual-corpora-predict-fast-memory-retrieval-Hofmann-Muller/c03d1820afdbd9cc5208ba3e73329c26958589d3},
	abstract = {The corpus, from which a predictive language model is trained, can be considered the experience of a semantic system. We recorded everyday reading of two participants for two months on a tablet, generating individual corpus samples of 300/500K tokens. Then we trained word2vec models from individual corpora and a 70 million-sentence newspaper corpus to obtain individual and norm-based long-term memory structure. To test whether individual corpora can make better predictions for a cognitive task of long-term memory retrieval, we generated stimulus materials consisting of 134 sentences with uncorrelated individual and norm-based word probabilities. For the subsequent eye tracking study 1-2 months later, our regression analyses revealed that individual, but not norm-corpus-based word probabilities can account for first-fixation duration and first-pass gaze duration. Word length additionally affected gaze duration and total viewing duration. The results suggest that corpora representative for an individual’s long-term memory structure can better explain reading performance than a norm corpus, and that recently acquired information is lexically accessed rapidly.},
	urldate = {2023-05-16},
	journal = {ArXiv},
	author = {Hofmann, M. and Muller, Lara and Rolke, A. and Radach, R. and Biemann, Chris},
	month = oct,
	year = {2020},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\TLU9DB87\\Hofmann et al. - 2020 - Individual corpora predict fast memory retrieval d.pdf:application/pdf},
}

@article{hofmann_language_2022,
	title = {Language {Models} {Explain} {Word} {Reading} {Times} {Better} {Than} {Empirical} {Predictability}},
	volume = {4},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2021.730570/full},
	doi = {10.3389/frai.2021.730570},
	abstract = {Though there is a strong consensus that word length and frequency are the most important single-word features determining visual-orthographic access to the mental lexicon, there is less agreement as how to best capture syntactic and semantic factors. The traditional approach in cognitive reading research assumes that word predictability from sentence context is best captured by cloze completion probability (CCP) derived from human performance data. We review recent research suggesting that probabilistic language models provide deeper explanations for syntactic and semantic effects than CCP. Then we compare CCP with three probabilistic language models for predicting word viewing times in an English and a German eye tracking sample: (1) Symbolic n-gram models consolidate syntactic and semantic short-range relations by computing the probability of a word to occur, given two preceding words. (2) Topic models rely on subsymbolic representations to capture long-range semantic similarity by word co-occurrence counts in documents. (3) In recurrent neural networks (RNNs), the subsymbolic units are trained to predict the next word, given all preceding words in the sentences. To examine lexical retrieval, these models were used to predict single fixation durations and gaze durations to capture rapidly successful and standard lexical access, and total viewing time to capture late semantic integration. The linear item-level analyses showed greater correlations of all language models with all eye-movement measures than CCP. Then we examined non-linear relations between the different types of predictability and the reading times using generalized additive models. N-gram and RNN probabilities of the present word more consistently predicted reading performance compared with topic models or CCP. For the effects of last-word probability on current-word viewing times, we obtained the best results with n-gram models. Such count-based models seem to best capture short-range access that is still underway when the eyes move on to the subsequent word. The prediction-trained RNN models, in contrast, better predicted early preprocessing of the next word. In sum, our results demonstrate that the different language models account for differential cognitive processes during reading. We discuss these algorithmically concrete blueprints of lexical consolidation as theoretically deep explanations for human reading.},
	urldate = {2023-05-16},
	journal = {Frontiers in Artificial Intelligence},
	author = {Hofmann, Markus J. and Remus, Steffen and Biemann, Chris and Radach, Ralph and Kuchinke, Lars},
	month = feb,
	year = {2022},
	pages = {730570},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\W7QNG7HE\\Hofmann et al. - 2022 - Language Models Explain Word Reading Times Better .pdf:application/pdf},
}

@article{baayen_demythologizing_2010,
	title = {Demythologizing the word frequency effect: {A} discriminative learning perspective},
	volume = {5},
	issn = {1871-1340, 1871-1375},
	shorttitle = {Demythologizing the word frequency effect},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ml.5.3.10baa},
	doi = {10.1075/ml.5.3.10baa},
	abstract = {This study starts from the hypothesis, first advanced by McDonald and Shillcock (2001), that the word frequency effect for a large part reflects local syntactic co-occurrence. It is shown that indeed the word frequency effect in the sense of pure repeated exposure accounts for only a small proportion of the variance in lexical decision, and that local syntactic and morphological co-occurrence probabilities are what makes word frequency a powerful predictor for lexical decision latencies. A comparison of two computational models, the cascaded dual route model (Coltheart, Rastle, Perry, Langdon, \& Ziegler, 2001) and the Naive Discriminative Reader (Baayen, Milin, Filipovic Durdjevic, Hendrix, \& Marelli, 2010), indicates that only the latter model properly captures the quantitative weight of the latent dimensions of lexical variation as predictors of response times. Computational models that account for frequency of occurrence by some mechanism equivalent to a counter in the head therefore run the risk of overestimating the role of frequency as repetition, of overestimating the importance of words’ form properties, and of underestimating the importance of contextual learning during past experience in proficient reading.},
	language = {en},
	number = {3},
	urldate = {2023-05-16},
	journal = {The Mental Lexicon},
	author = {Baayen, R. H.},
	month = dec,
	year = {2010},
	pages = {436--461},
}

@misc{baayen_celex_1993,
	address = {Philadelphia: Linguistic Data Consortium, University of Pennsylvania.},
	title = {The {CELEX} lexical database [cd-rom]},
	author = {Baayen, R. Harald and Piepenbrock, R and Van Rijn, H},
	year = {1993},
}

@book{baayen_analyzing_2008,
	address = {Cambridge},
	title = {Analyzing linguistic data: {A} practical introduction to statistics using {R}},
	isbn = {0-521-70918-0},
	shorttitle = {Analyzing {Linguistic} {Data}},
	publisher = {Cambridge University Press},
	author = {Baayen, R. H.},
	year = {2008},
}

@article{murakami_l1_2016,
	title = {L1 influence on the acquisition order of {English} grammatical morphemes: {A} learner corpus study},
	volume = {38},
	issn = {0272-2631, 1470-1545},
	shorttitle = {L1 {INFLUENCE} {ON} {THE} {ACQUISITION} {ORDER} {OF} {ENGLISH} {GRAMMATICAL} {MORPHEMES}},
	url = {https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/l1-influence-on-the-acquisition-order-of-english-grammatical-morphemes/3263C3E82ECA4A7EB19D8F50E45FA1C3},
	doi = {10.1017/S0272263115000352},
	abstract = {We revisit morpheme studies to evaluate the long-standing claim for a universal order of acquisition. We investigate the L2 acquisition order of six English grammatical morphemes by learners from seven L1 groups across five proficiency levels. Data are drawn from approximately 10,000 written exam scripts from the Cambridge Learner Corpus. The study establishes clear L1 influence on the absolute accuracy of morphemes and their acquisition order, therefore challenging the widely held view that there is a universal order of acquisition of L2 morphemes. Moreover, we find that L1 influence is morpheme specific, with morphemes encoding language-specific concepts most vulnerable to L1 influence.},
	language = {en},
	number = {3},
	urldate = {2018-11-27},
	journal = {Studies in Second Language Acquisition},
	author = {Murakami, Akira and Alexopoulou, Theodora},
	month = sep,
	year = {2016},
	pages = {365--401},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\4X5GUIEU\\Murakami and Alexopoulou - 2016 - L1 INFLUENCE ON THE ACQUISITION ORDER OF ENGLISH G.pdf:application/pdf;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\E9VQDFR9\\3263C3E82ECA4A7EB19D8F50E45FA1C3.html:text/html},
}

@misc{piantadosi_modern_2023,
	title = {Modern language models refute {Chomsky}’s approach to language},
	url = {https://lingbuzz.net/lingbuzz/007180},
	abstract = {The rise and success of large language models undermines virtually every strong claim for the innateness of language that has been proposed by generative linguistics. Modern machine learning has subverted and bypassed the entire theoretical framework of Chomsky's approach, including its core claims to particular insights, principles, structures, and processes. I describe the sense in which modern language models implement genuine theories of language, including representations of syntactic and semantic structure. I highlight the relationship between contemporary models and prior approaches in linguistics, namely those based on gradient computations and memorized constructions. I also respond to several critiques of large language models, including claims that they can't answer ``why'' questions, and skepticism that they are informative about real life acquisition. Most notably, large language models have attained remarkable success at discovering grammar without using any of the methods that some in linguistics insisted were necessary for a science of language to progress.},
	urldate = {2023-03-28},
	publisher = {LingBuzz},
	author = {Piantadosi, Steven},
	month = mar,
	year = {2023},
	note = {LingBuzz Published In:},
	keywords = {syntax, computational modeling, cognitive science, chomsky, emergent, generative syntax, large language model, minimalism, statistical learning},
	file = {LingBuzz Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\3CHCU857\\Piantadosi - 2023 - Modern language models refute Chomsky’s approach t.pdf:application/pdf;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\E4KV7QTS\\007180.html:text/html},
}

@article{binz_using_2023,
	title = {Using cognitive psychology to understand {GPT}-3},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2218523120},
	doi = {10.1073/pnas.2218523120},
	abstract = {We study GPT-3, a recent large language model, using tools from cognitive psychology. More specifically, we assess GPT-3’s decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature. We find that much of GPT-3’s behavior is impressive: It solves vignette-based tasks similarly or better than human subjects, is able to make decent decisions from descriptions, outperforms humans in a multiarmed bandit task, and shows signatures of model-based reinforcement learning. Yet, we also find that small perturbations to vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures of directed exploration, and that it fails miserably in a causal reasoning task. Taken together, these results enrich our understanding of current large language models and pave the way for future investigations using tools from cognitive psychology to study increasingly capable and opaque artificial agents.},
	number = {6},
	urldate = {2023-03-28},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Binz, Marcel and Schulz, Eric},
	month = feb,
	year = {2023},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2218523120},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\YQG2HT4A\\Binz and Schulz - 2023 - Using cognitive psychology to understand GPT-3.pdf:application/pdf},
}

@article{shiffrin_probing_2023,
	title = {Probing the psychology of {AI} models},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2300963120},
	doi = {10.1073/pnas.2300963120},
	number = {10},
	urldate = {2023-03-28},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Shiffrin, Richard and Mitchell, Melanie},
	month = mar,
	year = {2023},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2300963120},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\QTYT43WQ\\Shiffrin and Mitchell - 2023 - Probing the psychology of AI models.pdf:application/pdf},
}

@misc{lehner_mehr_2023,
	title = {Mehr als {ChatGPT}: {EU} will {KI} die {Grenzen} aufzeigen},
	shorttitle = {Mehr als {ChatGPT}},
	url = {https://orf.at/stories/3308939/},
	abstract = {Der Chatbot ChatGPT hat künstliche Intelligenz (KI) und ihre Risiken in den Fokus der Öffentlichkeit gerückt. Dabei wird KI längst in vielen Bereichen eingesetzt. Brüssel will der Technologie deshalb Grenzen aufzeigen. Doch die Debatten über ein geplantes Gesetz zur Regulierung der KI wollen nicht abreißen. Während die einen ein Zuviel an Regulierung fürchten, warnen die anderen vor einer zu löchrigen Gesetzgebung.},
	language = {de},
	urldate = {2023-03-23},
	journal = {news.ORF.at},
	author = {Lehner, Katja and Brüssel, aus and {ORF.at}},
	month = mar,
	year = {2023},
}

@inproceedings{liesenfeld_building_2022,
	address = {Marseille, France},
	title = {Building and curating conversational corpora for diversity-aware language science and technology},
	url = {https://aclanthology.org/2022.lrec-1.126},
	abstract = {We present an analysis pipeline and best practice guidelines for building and curating corpora of everyday conversation in diverse languages. Surveying language documentation corpora and other resources that cover 67 languages and varieties from 28 phyla, we describe the compilation and curation process, specify minimal properties of a unified format for interactional data, and develop methods for quality control that take into account turn-taking and timing. Two case studies show the broad utility of conversational data for (i) charting human interactional infrastructure and (ii) tracing challenges and opportunities for current ASR solutions. Linguistically diverse conversational corpora can provide new insights for the language sciences and stronger empirical foundations for language technology.},
	urldate = {2023-03-23},
	booktitle = {Proceedings of the {Thirteenth} {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Liesenfeld, Andreas and Dingemanse, Mark},
	month = jun,
	year = {2022},
	pages = {1178--1192},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\CPGDHB3Y\\Liesenfeld and Dingemanse - 2022 - Building and curating conversational corpora for d.pdf:application/pdf},
}

@misc{ludewig_what_2022,
	title = {What {Text} {Features} {Make} {Reading} {Comprehension} {Difficult} {Across} {Elementary} {School}? {Investigating} {Difficulty} and {Changes} in {Difficulty}},
	shorttitle = {What {Text} {Features} {Make} {Reading} {Comprehension} {Difficult} {Across} {Elementary} {School}?},
	url = {https://psyarxiv.com/axkbv/},
	doi = {10.31234/osf.io/axkbv},
	abstract = {Beginning readers benefit in most situations from reading activities that are neither too difficult nor too easy. This study investigated which text features make reading comprehension difficult for third and fourth grade elementary school students. Specifically, 145 multiple-choice items from a reading comprehension test used in several cross-sectional studies (G3: N = 1387; G4: N = 868) and a longitudinal sub-study (N = 195) were analyzed using explanatory item response models to explain item difficulty and changes in item difficulty across grades. A multi-step feature selection procedure controlling for seven task features led to the selection of eight text features from a total of 268 linguistic text features examined. The results showed that lexical and syntactic features and text genre were the most relevant features and that the importance of specific text features changes from third to fourth grade. Expository text were more difficult on average than narrative texts. This difference was only partially explained by lexical and syntactic features in third grade, but almost completely in fourth grade. The results suggest that text features have a dynamic effect on reading comprehension difficulty throughout third to fourth grade; this is especially true of text genre. Our results can help to select more appropriate texts for elementary students and to improve our understanding of the complex interaction between reader, text and activity as it develops over time.},
	language = {en-us},
	urldate = {2023-03-22},
	publisher = {PsyArXiv},
	author = {Ludewig, Ulrich and Trendtel, Matthias and Weiss, Zarah and Meurers, Detmar and McElvany, Nele},
	month = jun,
	year = {2022},
	keywords = {Linguistic complexity, Educational Psychology, Elementary school, Learner, Reading comprehension, Social and Behavioral Sciences, Text genre},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\XANBBENZ\\Ludewig et al. - 2022 - What Text Features Make Reading Comprehension Diff.pdf:application/pdf},
}

@article{weiss_analyzing_2021,
	title = {Analyzing the linguistic complexity of {German} learner language in a reading comprehension task: {Using} proficiency classification to investigate short answer data, cross-data generalizability, and the impact of linguistic analysis quality},
	volume = {7},
	issn = {2215-1478, 2215-1486},
	shorttitle = {Analyzing the linguistic complexity of {German} learner language in a reading comprehension task},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ijlcr.20006.wei},
	doi = {10.1075/ijlcr.20006.wei},
	abstract = {Abstract While traditionally linguistic complexity analysis of learner language is mostly based on essays, there is increasing interest in other task types. This is crucial for obtaining a broader empirical basis for characterizing language proficiency and highlights the need to advance our understanding of how task and learner properties interact in shaping the linguistic complexity of learner productions. It also makes it important to determine which complexity measures generalize well across which tasks. In this paper, we investigate the linguistic complexity of answers to reading comprehension questions written by foreign language learners of German at the college level. Analyzing the corpus with computational linguistic methods identifying a wide range of complexity features, we explore which linguistic complexity analyses can successfully be performed for such short answers, how learner proficiency impacts the results, how generalizable they are across different contexts, and how the quality of the underlying analysis impacts the results.},
	language = {en},
	number = {1},
	urldate = {2021-07-05},
	journal = {International Journal of Learner Corpus Research},
	author = {Weiss, Zarah and Meurers, Detmar},
	month = mar,
	year = {2021},
	note = {00000 
Publisher: John Benjamins},
	pages = {83--130},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\YRYGEUPF\\ijlcr.20006.html:text/html},
}

@article{brysbaert_word_2018,
	title = {The word frequency effect in word processing: {An} updated review},
	volume = {27},
	shorttitle = {The word frequency effect in word processing},
	number = {1},
	journal = {Current Directions in Psychological Science},
	author = {Brysbaert, Marc and Mandera, Pawe{\textbackslash}l and Keuleers, Emmanuel},
	year = {2018},
	note = {Publisher: Sage Publications Sage CA: Los Angeles, CA},
	pages = {45--50},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\KG6RDQQD\\Brysbaert et al. - 2018 - The word frequency effect in word processing An u.pdf:application/pdf},
}

@article{keuleers_british_2010,
	title = {The {British} {Lexicon} {Project}: {Lexical} decision data for 28,730 monosyllabic and disyllabic {English} words},
	volume = {1},
	shorttitle = {The {British} {Lexicon} {Project}},
	journal = {Psychology},
	author = {Keuleers, Emmanuel and Lacey, Paula and Rastle, Kathleen and Brysbaert, Marc},
	year = {2010},
	note = {Publisher: Citeseer},
	pages = {174},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\CEUJA8DZ\\Keuleers et al. - 2010 - The British Lexicon Project Lexical decision data.pdf:application/pdf},
}

@article{ferrand_french_2010,
	title = {The {French} {Lexicon} {Project}: {Lexical} decision data for 38,840 {French} words and 38,840 pseudowords},
	volume = {42},
	shorttitle = {The {French} {Lexicon} {Project}},
	journal = {Behavior research methods},
	author = {Ferrand, Ludovic and New, Boris and Brysbaert, Marc and Keuleers, Emmanuel and Bonin, Patrick and Méot, Alain and Augustinova, Maria and Pallier, Christophe},
	year = {2010},
	note = {Publisher: Springer},
	pages = {488--496},
}

@article{van_heuven_subtlex-uk_2014,
	title = {{SUBTLEX}-{UK}: {A} new and improved word frequency database for {British} {English}},
	volume = {67},
	shorttitle = {{SUBTLEX}-{UK}},
	number = {6},
	journal = {Quarterly journal of experimental psychology},
	author = {Van Heuven, Walter JB and Mandera, Pawel and Keuleers, Emmanuel and Brysbaert, Marc},
	year = {2014},
	note = {Publisher: SAGE Publications Sage UK: London, England},
	pages = {1176--1190},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\PRC4EAAE\\Van Heuven et al. - 2014 - SUBTLEX-UK A new and improved word frequency data.pdf:application/pdf},
}

@misc{wild_ratte_nodate,
	title = {Ratte. {Regensburger} {Analysetool} für {Texte}. {Version} 2.0.},
	url = {https://www.uni-regensburg.de/sprache-literatur-kultur/germanistik-did/downloads/ratte/index.html},
	urldate = {2023-05-05},
	author = {Wild, J and Pissarek, M},
	file = {Ratte - Universität Regensburg:C\:\\Users\\jobsc\\Zotero\\storage\\49ZDE5UW\\index.html:text/html},
}

@article{hasenacker_comparing_2019,
	title = {Comparing length and frequency effects in children across modalities},
	volume = {72},
	issn = {1747-0218},
	url = {https://doi.org/10.1177/1747021818805063},
	doi = {10.1177/1747021818805063},
	abstract = {Although it is well established that beginning readers rely heavily on phonological decoding, the overlap of the phonological pathways used in visual and auditory word recognition is not clear. Especially in transparent languages, phonological reading could use the same pathways as spoken word processing. In the present study, we report a direct comparison of lexical decision performance in the visual and auditory modality in beginning readers of a transparent language. Using lexical decision, we examine how marker effects of length and frequency differ in the two modalities and how these differences are modulated by reading ability. The results show that both frequency and length effects are stronger in the visual modality, and the differences in length effects between modalities are more pronounced for poorer readers than for better readers. This suggests that visual word recognition in beginning readers of a transparent language initially is based on phonological decoding and subsequent matching in the phonological lexicon, especially for poor readers. However, some orthographic processing seems to be involved already. We claim that the relative contribution of the phonological and orthographic route in beginning readers can be measured by the differences in marker effects between auditory and visual lexical decision.},
	language = {en},
	number = {7},
	urldate = {2023-05-04},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Hasenäcker, Jana and Verra, Luianta and Schroeder, Sascha},
	month = jul,
	year = {2019},
	note = {Publisher: SAGE Publications},
	pages = {1682--1691},
}

@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {1566-2535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	language = {en},
	urldate = {2023-04-27},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	keywords = {Accountability, Comprehensibility, Data Fusion, Deep Learning, Explainable Artificial Intelligence, Fairness, Interpretability, Machine Learning, Privacy, Responsible Artificial Intelligence, Transparency},
	pages = {82--115},
	file = {Accepted Version:C\:\\Users\\jobsc\\Zotero\\storage\\MZQB7RG8\\Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\PKMMAGQV\\S1566253519308103.html:text/html},
}

@misc{cai_does_2023,
	title = {Does {ChatGPT} resemble humans in language use?},
	url = {http://arxiv.org/abs/2303.08014},
	doi = {10.48550/arXiv.2303.08014},
	abstract = {Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities according to verb semantics, and accessed different meanings and retrieved different words depending on the identity of its interlocutor. However, unlike humans, it did not prefer using shorter words to convey less informative content and it did not use context to disambiguate syntactic ambiguities. We discuss how these convergences and divergences may occur in the transformer architecture. Overall, these experiments demonstrate that LLM-driven chatbots like ChatGPT are capable of mimicking human language processing to a great extent, and that they have the potential to provide insights into how people learn and use language.},
	urldate = {2023-04-25},
	publisher = {arXiv},
	author = {Cai, Zhenguang G. and Haslett, David A. and Duan, Xufeng and Wang, Shuqi and Pickering, Martin J.},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08014 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\ZM86I5LL\\Cai et al. - 2023 - Does ChatGPT resemble humans in language use.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\4INAV3HN\\2303.html:text/html},
}

@misc{chang_language_2023,
	title = {Language {Model} {Behavior}: {A} {Comprehensive} {Survey}},
	shorttitle = {Language {Model} {Behavior}},
	url = {http://arxiv.org/abs/2303.11504},
	doi = {10.48550/arXiv.2303.11504},
	abstract = {Transformer language models have received widespread public attention, yet their generated text is often surprising even to NLP researchers. In this survey, we discuss over 250 recent studies of English language model behavior before task-specific fine-tuning. Language models possess basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but these capabilities are sensitive to specific inputs and surface features. Despite dramatic increases in generated text quality as models scale to hundreds of billions of parameters, the models are still prone to unfactual responses, commonsense errors, memorized text, and social biases. Many of these weaknesses can be framed as over-generalizations or under-generalizations of learned patterns in text. We synthesize recent results to highlight what is currently known about what large language models can and cannot do.},
	urldate = {2023-04-25},
	publisher = {arXiv},
	author = {Chang, Tyler A. and Bergen, Benjamin K.},
	month = mar,
	year = {2023},
	note = {arXiv:2303.11504 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\G8UIB2AE\\Chang and Bergen - 2023 - Language Model Behavior A Comprehensive Survey.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\WW5UHF9C\\2303.html:text/html},
}

@misc{zhao_survey_2023,
	title = {A {Survey} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2303.18223},
	doi = {10.48550/arXiv.2303.18223},
	abstract = {Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.},
	urldate = {2023-04-25},
	publisher = {arXiv},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	month = apr,
	year = {2023},
	note = {arXiv:2303.18223 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\Y5Y6T8N9\\Zhao et al. - 2023 - A Survey of Large Language Models.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\3KZAPXC9\\2303.html:text/html},
}

@misc{park_correct_2023,
	title = {"{Correct} answers" from the psychology of artificial intelligence},
	url = {http://arxiv.org/abs/2302.07267},
	doi = {10.48550/arXiv.2302.07267},
	abstract = {We re-replicate 14 psychology studies from the Many Labs 2 replication project (Klein et al., 2018) with OpenAI's text-davinci-003 model, colloquially known as GPT3.5. Among the eight studies we could analyse, our GPT sample replicated 37.5\% of the original results and 37.5\% of the Many Labs 2 results. We could not analyse the remaining six studies, due to an unexpected phenomenon we call the "correct answer" effect. Different runs of GPT3.5 answered nuanced questions probing political orientation, economic preference, judgement, and moral philosophy with zero or near-zero variation in responses: with the supposedly "correct answer." Most but not all of these "correct answers" were robust to changing the order of answer choices. One exception occurred in the Moral Foundations Theory survey (Graham et al., 2009), for which GPT3.5 almost always identified as a conservative in the original condition (N=1,030, 99.6\%) and as a liberal in the reverse-order condition (N=1,030, 99.3\%). GPT3.5's responses to subsequent questions revealed post-hoc rationalisation; there was a relative bias in the direction of its previously reported political orientation. But both self-reported GPT conservatives and self-reported GPT liberals revealed right-leaning Moral Foundations, although the right-leaning bias of self-reported GPT liberals was weaker. We hypothesise that this pattern was learned from a conservative bias in the model's largely Internet-based training data. Since AI models of the future may be trained on much of the same Internet data as GPT3.5, our results raise concerns that a hypothetical AI-led future may be subject to a diminished diversity of thought.},
	urldate = {2023-04-25},
	publisher = {arXiv},
	author = {Park, Peter S. and Schoenegger, Philipp and Zhu, Chongyang},
	month = apr,
	year = {2023},
	note = {arXiv:2302.07267 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, 68T50, Computer Science - Human-Computer Interaction, I.2.7},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\FW3Y23QQ\\Park et al. - 2023 - Correct answers from the psychology of artificia.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\SYRNT83Y\\2302.html:text/html},
}

@misc{binz_meta-learned_2023,
	title = {Meta-{Learned} {Models} of {Cognition}},
	url = {http://arxiv.org/abs/2304.06729},
	doi = {10.48550/arXiv.2304.06729},
	abstract = {Meta-learning is a framework for learning learning algorithms through repeated interactions with an environment as opposed to designing them by hand. In recent years, this framework has established itself as a promising tool for building models of human cognition. Yet, a coherent research program around meta-learned models of cognition is still missing. The purpose of this article is to synthesize previous work in this field and establish such a research program. We rely on three key pillars to accomplish this goal. We first point out that meta-learning can be used to construct Bayes-optimal learning algorithms. This result not only implies that any behavioral phenomenon that can be explained by a Bayesian model can also be explained by a meta-learned model but also allows us to draw strong connections to the rational analysis of cognition. We then discuss several advantages of the meta-learning framework over traditional Bayesian methods. In particular, we argue that meta-learning can be applied to situations where Bayesian inference is impossible and that it enables us to make rational models of cognition more realistic, either by incorporating limited computational resources or neuroscientific knowledge. Finally, we reexamine prior studies from psychology and neuroscience that have applied meta-learning and put them into the context of these new insights. In summary, our work highlights that meta-learning considerably extends the scope of rational analysis and thereby of cognitive theories more generally.},
	urldate = {2023-04-25},
	publisher = {arXiv},
	author = {Binz, Marcel and Dasgupta, Ishita and Jagadish, Akshay and Botvinick, Matthew and Wang, Jane X. and Schulz, Eric},
	month = apr,
	year = {2023},
	note = {arXiv:2304.06729 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\5GR85A3W\\Binz et al. - 2023 - Meta-Learned Models of Cognition.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\ZYCQ6X28\\2304.html:text/html},
}

@misc{pellert_ai_2022,
	title = {{AI} {Psychometrics}: {Using} psychometric inventories to obtain psychological profiles of large language models},
	shorttitle = {{AI} {Psychometrics}},
	url = {https://psyarxiv.com/jv5dt/},
	doi = {10.31234/osf.io/jv5dt},
	abstract = {In this perspective article, we argue that it is possible that systems built on large language models exhibit psychological traits that have so far been studied only in humans. Whereas we do not aim to anthropomorphize artificial intelligence, we argue that because large language models are trained on vast corpora of text that often contain statements about human values, attitudes, beliefs, and personality traits, such models will have learned a set of psychological characteristics that ultimately gives a unique "psychological" makeup to every such model. This psychological makeup can manifest in the model's outputs. Therefore, it should be possible to assess these characteristics by applying psychometric assessments to these models. In a series of demonstrations, we provide various models with psychometric questionnaire items as input and "ask" them to choose an answer as output. Their responses open a pathway to exploring potential biases ingrained in large language models in a rich way, and ultimately may help to avoid the development of large language models that induce harm when deployed in broader societal applications. We conclude by arguing that our investigations give rise to a new interdisciplinary field of research that we would refer to as 'AI Psychometrics'. We propose that AI Psychometrics should focus on tackling the manifold research opportunities and challenges that emerge when deploying psychometric tests to large language models.},
	language = {en-us},
	urldate = {2023-04-25},
	publisher = {PsyArXiv},
	author = {Pellert, Max and Lechner, Clemens and Wagner, Claudia and Rammstedt, Beatrice and Strohmaier, Markus},
	month = dec,
	year = {2022},
	keywords = {Psychology, NLP, Psychometrics, Social and Behavioral Sciences, AI, Gender/Sex Diversity Beliefs, Large Language Models, LLM, Moral Foundations, Natural Language Inference, Natural Language Processing, NLI, other, Personality, Quantitative Methods, Values},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\FKXPLUCR\\Pellert et al. - 2022 - AI Psychometrics Using psychometric inventories t.pdf:application/pdf},
}

@article{tellings_basilex_2014,
	title = {{BasiLex}: {An} 11.5 million words corpus of {Dutch} texts written for children},
	volume = {4},
	shorttitle = {{BasiLex}},
	journal = {Computational Linguistics in the Netherlands Journal},
	author = {Tellings, Agnes and Hulsbosch, Micha and Vermeer, Anne and Van den Bosch, Antal},
	year = {2014},
	pages = {191--208},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\PXG89IYC\\Tellings et al. - BasiLex an 11.5 million words corpus of Dutch tex.pdf:application/pdf;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\HUDSI43P\\50.html:text/html},
}

@article{davies_reading_2017,
	title = {Reading through the life span: {Individual} differences in psycholinguistic effects},
	volume = {43},
	issn = {1939-1285},
	shorttitle = {Reading through the life span},
	doi = {10.1037/xlm0000366},
	abstract = {The effects of psycholinguistic variables are critical to the evaluation of theories about the cognitive reading system. However, reading research has tended to focus on the impact of key variables on average performance. We report the first investigation examining variation in psycholinguistic effects across the life span, from childhood into old age. We analyzed the performance of a sample of 535 readers, aged 8–83 years in lexical decision and pronunciation tasks. Our findings show that the effects on reading of two key variables, frequency and AoA, decrease in size with increasing age over the life span. We observed the systematic modulation by age and reading ability of these and other psycholinguistic effects alongside a global U-shaped effect of age. Diffusion model analyses suggest that developmental speed-up in decision responses can be attributed to the increasing quality of evidence accumulation in reaction to words, while the ageing-related slowing can be attributed to decreasing efficiency of stimulus encoding or response execution processes. An analysis of spoken response durations furnishes a consistent picture in which the slowing of pronunciation responses with age can be attributed to slowing articulatory processes. We think our findings can be explained by theoretical accounts that incorporate learning as the basis for the development of structure in the reading system. However, an adequate theory shall have to include assumptions about both developmental learning and later ageing. Our results warrant a life span theory of reading. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {Davies, Rob A. I. and Arnell, Ruth and Birchenough, Julia M. H. and Grimmond, Debbie and Houlson, Sam},
	year = {2017},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Aging, Psycholinguistics, Childhood Development, Life Span, Individual Differences, Reading Development, Word Recognition},
	pages = {1298--1338},
	file = {Accepted Version:C\:\\Users\\jobsc\\Zotero\\storage\\TBVLMHSP\\Davies et al. - 2017 - Reading through the life span Individual differen.pdf:application/pdf},
}

@article{van_den_boer_lexical_2012,
	title = {Lexical decision in children: {Sublexical} processing or lexical search?},
	volume = {65},
	shorttitle = {Lexical decision in children},
	number = {6},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {van den Boer, Madelon and de Jong, Peter F. and Haentjens-van Meeteren, Marleen M.},
	year = {2012},
	note = {Publisher: SAGE Publications Sage UK: London, England},
	pages = {1214--1228},
}

@article{monster_word_2022,
	title = {Word {Properties} {Predicting} {Children}’s {Word} {Recognition}},
	volume = {26},
	issn = {1088-8438},
	url = {https://doi.org/10.1080/10888438.2021.2020795},
	doi = {10.1080/10888438.2021.2020795},
	abstract = {We examined whether word recognition accuracy and latency of words children encounter during primary school across the upper primary school grades can be predicted from word form (word length, mean Levenshtein distance, and mean frequency of neighbors), word meaning (free association network markers) and word exposure (corpus frequency and contextual diversity). As a measure of word recognition, 1454 children (M = 10.1 years, SD = 11.8 months, 52.4\% girls) in grade 3, 4 and 5 of Dutch regular primary schools completed a lexical decision task. Confirmatory factor analyses showed that word characteristics could be reduced to latent constructs of form, meaning, and exposure. Structural equation models indicated that word form and exposure predicted word recognition accuracy, and that word recognition accuracy, word form, and word meaning predicted word recognition latency. The present study provided empirical evidence that word form, word meaning, and word exposure differentially predict word recognition accuracy and latency of words children encounter during primary school across the upper primary grades.},
	number = {5},
	urldate = {2023-04-18},
	journal = {Scientific Studies of Reading},
	author = {Monster, Iris and Tellings, Agnes and Burk, William J. and Keuning, Jos and Segers, Eliane and Verhoeven, Ludo},
	month = sep,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10888438.2021.2020795},
	pages = {373--389},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\RVGKGLSE\\Monster et al. - 2022 - Word Properties Predicting Children’s Word Recogni.pdf:application/pdf},
}

@article{behrens_inputoutput_2006,
	title = {The input–output relationship in first language acquisition},
	volume = {21},
	number = {1-3},
	journal = {Language and cognitive processes},
	author = {Behrens, Heike},
	year = {2006},
	note = {Publisher: Taylor \& Francis},
	pages = {2--24},
}

@article{koch_traceback_2022,
	title = {The traceback method and the early constructicon: theoretical and methodological considerations},
	volume = {18},
	issn = {1613-7035},
	shorttitle = {The traceback method and the early constructicon},
	url = {https://www.degruyter.com/document/doi/10.1515/cllt-2020-0045/html?lang=de},
	doi = {10.1515/cllt-2020-0045},
	abstract = {Usage-based approaches assume that children’s early utterances are item-based. This has been demonstrated in a number of studies using the traceback method. In this approach, a small amount of “target utterances” from a child language corpus is “traced back” to earlier utterances. Drawing on a case study of German, this paper provides a critical evaluation of the method from a usage-based perspective. In particular, we check how factors inherent to corpus data as well as methodological choices influence the results of traceback studies. To this end, we present four case studies in which we change thresholds and the composition of the main corpus, use a cross-corpus approach tracing one child’s utterances back to another child’s corpus, and reverse and randomize the target utterances. Overall, the results show that the method can provide interesting insights—particularly regarding different pathways of language acquisition—but they also show the limitations of the method.},
	language = {en},
	number = {3},
	urldate = {2023-04-17},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Koch, Nikolas and Hartmann, Stefan and Quick, Antje Endesfelder},
	month = oct,
	year = {2022},
	note = {Publisher: De Gruyter Mouton},
	keywords = {language acquisition, construction grammar, traceback, usage-based model},
	pages = {477--504},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\BGWX8C8L\\Koch et al. - 2022 - The traceback method and the early constructicon .pdf:application/pdf},
}

@misc{ignat_phd_2023,
	title = {A {PhD} {Student}'s {Perspective} on {Research} in {NLP} in the {Era} of {Very} {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2305.12544},
	doi = {10.48550/arXiv.2305.12544},
	abstract = {Recent progress in large language models has enabled the deployment of many generative NLP applications. At the same time, it has also led to a misleading public discourse that ``it's all been solved.'' Not surprisingly, this has in turn made many NLP researchers -- especially those at the beginning of their career -- wonder about what NLP research area they should focus on. This document is a compilation of NLP research directions that are rich for exploration, reflecting the views of a diverse group of PhD students in an academic research lab. While we identify many research areas, many others exist; we do not cover those areas that are currently addressed by LLMs but where LLMs lag behind in performance, or those focused on LLM development. We welcome suggestions for other research directions to include: https://bit.ly/nlp-era-llm},
	urldate = {2023-06-05},
	publisher = {arXiv},
	author = {Ignat, Oana and Jin, Zhijing and Abzaliev, Artem and Biester, Laura and Castro, Santiago and Deng, Naihao and Gao, Xinyi and Gunal, Aylin and He, Jacky and Kazemi, Ashkan and Khalifa, Muhammad and Koh, Namho and Lee, Andrew and Liu, Siyang and Min, Do June and Mori, Shinka and Nwatu, Joan and Perez-Rosas, Veronica and Shen, Siqi and Wang, Zekun and Wu, Winston and Mihalcea, Rada},
	month = may,
	year = {2023},
	note = {arXiv:2305.12544 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\N8VTBY6V\\Ignat et al. - 2023 - A PhD Student's Perspective on Research in NLP in .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\452QL8L3\\2305.html:text/html},
}

@article{graf_faktorenanalyse_2005,
	title = {Faktorenanalyse von 57 {Variablen} der visuellen {Worterkennung}},
	volume = {213},
	number = {4},
	journal = {Zeitschrift für Psychologie/Journal of Psychology},
	author = {Graf, Ralf and Nagler, Markus and Jacobs, Arthur M.},
	year = {2005},
	note = {Publisher: Hogrefe Verlag Göttingen},
	pages = {205--218},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\APGZQ9K8\\0044-3409.213.4.html:text/html},
}

@article{jurish_word_2013,
	title = {Word and sentence tokenization with {Hidden} {Markov} {Models}},
	volume = {28},
	number = {2},
	journal = {Journal for Language Technology and Computational Linguistics},
	author = {Jurish, Bryan and Würzner, Kay-Michael},
	year = {2013},
	pages = {61--83},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\XKHS6DVT\\Jurish and Würzner - 2013 - Word and sentence tokenization with Hidden Markov .pdf:application/pdf},
}

@misc{diamond_genlangs_2023,
	title = {"{Genlangs}" and {Zipf}'s {Law}: {Do} languages generated by {ChatGPT} statistically look human?},
	shorttitle = {"{Genlangs}" and {Zipf}'s {Law}},
	url = {http://arxiv.org/abs/2304.12191},
	doi = {10.48550/arXiv.2304.12191},
	abstract = {OpenAI's GPT-4 is a Large Language Model (LLM) that can generate coherent constructed languages, or "conlangs," which we propose be called "genlangs" when generated by Artificial Intelligence (AI). The genlangs created by ChatGPT for this research (Voxphera, Vivenzia, and Lumivoxa) each have unique features, appear facially coherent, and plausibly "translate" into English. This study investigates whether genlangs created by ChatGPT follow Zipf's law. Zipf's law approximately holds across all natural and artificially constructed human languages. According to Zipf's law, the word frequencies in a text corpus are inversely proportional to their rank in the frequency table. This means that the most frequent word appears about twice as often as the second most frequent word, three times as often as the third most frequent word, and so on. We hypothesize that Zipf's law will hold for genlangs because (1) genlangs created by ChatGPT fundamentally operate in the same way as human language with respect to the semantic usefulness of certain tokens, and (2) ChatGPT has been trained on a corpora of text that includes many different languages, all of which exhibit Zipf's law to varying degrees. Through statistical linguistics, we aim to understand if LLM-based languages statistically look human. Our findings indicate that genlangs adhere closely to Zipf's law, supporting the hypothesis that genlangs created by ChatGPT exhibit similar statistical properties to natural and artificial human languages. We also conclude that with human assistance, AI is already capable of creating the world's first fully-functional genlang, and we call for its development.},
	urldate = {2023-06-29},
	publisher = {arXiv},
	author = {Diamond, Justin},
	month = mar,
	year = {2023},
	note = {arXiv:2304.12191 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\P4FMCX4G\\Diamond - 2023 - Genlangs and Zipf's Law Do languages generated .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\TSKCW8BS\\2304.html:text/html},
}

@article{feinerer_text_2008,
	title = {Text {Mining} {Infrastructure} in {R}},
	volume = {25},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v25/i05/},
	doi = {10.18637/jss.v025.i05},
	language = {en},
	number = {5},
	urldate = {2023-07-06},
	journal = {Journal of Statistical Software},
	author = {Feinerer, Ingo and Hornik, Kurt and Meyer, David},
	year = {2008},
	file = {Accepted Version:C\:\\Users\\jobsc\\Zotero\\storage\\ZIEL98MJ\\Feinerer et al. - 2008 - Text Mining Infrastructure in R.pdf:application/pdf},
}

@misc{wijffels_udpipe_2023,
	title = {udpipe: {Tokenization}, {Parts} of {Speech} {Tagging}, {Lemmatization} and {Dependency} {Parsing} with the '{UDPipe}' '{NLP}' {Toolkit}},
	copyright = {MPL-2.0},
	shorttitle = {udpipe},
	url = {https://cran.r-project.org/web/packages/udpipe/index.html},
	abstract = {This natural language processing toolkit provides language-agnostic 'tokenization', 'parts of speech tagging', 'lemmatization' and 'dependency parsing' of raw text. Next to text parsing, the package also allows you to train annotation models based on data of 'treebanks' in 'CoNLL-U' format as provided at {\textless}https://universaldependencies.org/format.html{\textgreater}. The techniques are explained in detail in the paper: 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', available at {\textless}doi:10.18653/v1/K17-3009{\textgreater}. The toolkit also contains functionalities for commonly used data manipulations on texts which are enriched with the output of the parser. Namely functionalities and algorithms for collocations, token co-occurrence, document term matrix handling, term frequency inverse document frequency calculations, information retrieval metrics (Okapi BM25), handling of multi-word expressions, keyword detection (Rapid Automatic Keyword Extraction, noun phrase extraction, syntactical patterns) sentiment scoring and semantic similarity analysis.},
	urldate = {2023-07-06},
	author = {Wijffels, Jan and BNOSAC and Linguistics, Institute of Formal {and} Applied and Physics, Faculty of Mathematics and and Prague, Charles University in and Republic, Czech and Straka, Milan and Straková, Jana},
	month = jan,
	year = {2023},
	keywords = {NaturalLanguageProcessing},
}

@inproceedings{straka_tokenizing_2017,
	address = {Vancouver, Canada},
	title = {Tokenizing, {POS} {Tagging}, {Lemmatizing} and {Parsing} {UD} 2.0 with {UDPipe}},
	url = {http://www.aclweb.org/anthology/K/K17/K17-3009.pdf},
	booktitle = {Proceedings of the {CoNLL} 2017 {Shared} {Task}: {Multilingual} {Parsing} from {Raw} {Text} to {Universal} {Dependencies}},
	publisher = {Association for Computational Linguistics},
	author = {Straka, Milan and Straková, Jana},
	month = aug,
	year = {2017},
	pages = {88--99},
}

@article{nivre_universal_2017,
	title = {Universal {Dependencies} 2.0},
	copyright = {Licence Universal Dependencies v2.0},
	url = {https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1983},
	abstract = {Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008). 
 
This release is special in that the treebanks will be used as training/development data in the CoNLL 2017 shared task (http://universaldependencies.org/conll17/). Test data are not released, except for the few treebanks that do not take part in the shared task. 64 treebanks will be in the shared task, and they correspond to the following 45 languages: Ancient Greek, Arabic, Basque, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Gothic, Greek, Hebrew, Hindi, Hungarian, Indonesian, Irish, Italian, Japanese, Kazakh, Korean, Latin, Latvian, Norwegian, Old Church Slavonic, Persian, Polish, Portuguese, Romanian, Russian, Slovak, Slovenian, Spanish, Swedish, Turkish, Ukrainian, Urdu, Uyghur and Vietnamese. 
 
This release fixes a bug in http://hdl.handle.net/11234/1-1976. Changed files: ud-tools-v2.0.tgz (conllu\_to\_text.pl, conllu\_to\_conllx.pl; added text\_without\_spaces.pl), ud-treebanks-conll2017.tgz (fi\_ftb-ud-train.txt, he-ud-train.txt, it-ud-train.txt, pt\_br-ud-train.txt, es-ud-train.txt) and ud-treebanks-v2.0.tgz (fi\_ftb-ud-train.txt, he-ud-train.txt, it-ud-train.txt, pt\_br-ud-train.txt, es-ud-train.txt, ar\_nyuad-ud-dev.txt, ar\_nyuad-ud-test.txt, ar\_nyuad-ud-train.txt, cop-ud-dev.txt, cop-ud-test.txt, cop-ud-train.txt, sa-ud-dev.txt, sa-ud-test.txt, sa-ud-train.txt).},
	language = {grc},
	urldate = {2023-07-06},
	journal = {http://universaldependencies.org/},
	author = {Nivre, Joakim and Agić, Željko and Ahrenberg, Lars and Aranzabe, Maria Jesus and Asahara, Masayuki and Atutxa, Aitziber and Ballesteros, Miguel and Bauer, John and Bengoetxea, Kepa and Bhat, Riyaz Ahmad and Bick, Eckhard and Bosco, Cristina and Bouma, Gosse and Bowman, Sam and Candito, Marie and Cebiroğlu Eryiğit, Gülşen and Celano, Giuseppe G. A. and Chalub, Fabricio and Choi, Jinho and Çöltekin, Çağrı and Connor, Miriam and Davidson, Elizabeth and de Marneffe, Marie-Catherine and de Paiva, Valeria and Diaz de Ilarraza, Arantza and Dobrovoljc, Kaja and Dozat, Timothy and Droganova, Kira and Dwivedi, Puneet and Eli, Marhaba and Erjavec, Tomaž and Farkas, Richárd and Foster, Jennifer and Freitas, Cláudia and Gajdošová, Katarína and Galbraith, Daniel and Garcia, Marcos and Ginter, Filip and Goenaga, Iakes and Gojenola, Koldo and Gökırmak, Memduh and Goldberg, Yoav and Gómez Guinovart, Xavier and Gonzáles Saavedra, Berta and Grioni, Matias and Grūzītis, Normunds and Guillaume, Bruno and Habash, Nizar and Hajič, Jan and Hà Mỹ, Linh and Haug, Dag and Hladká, Barbora and Hohle, Petter and Ion, Radu and Irimia, Elena and Johannsen, Anders and Jørgensen, Fredrik and Kaşıkara, Hüner and Kanayama, Hiroshi and Kanerva, Jenna and Kotsyba, Natalia and Krek, Simon and Laippala, Veronika and Lê Hồng, Phương and Lenci, Alessandro and Ljubešić, Nikola and Lyashevskaya, Olga and Lynn, Teresa and Makazhanov, Aibek and Manning, Christopher and Mărănduc, Cătălina and Mareček, David and Martínez Alonso, Héctor and Martins, André and Mašek, Jan and Matsumoto, Yuji and McDonald, Ryan and Missilä, Anna and Mititelu, Verginica and Miyao, Yusuke and Montemagni, Simonetta and More, Amir and Mori, Shunsuke and Moskalevskyi, Bohdan and Muischnek, Kadri and Mustafina, Nina and Müürisep, Kaili and Nguyễn Thị, Lương and Nguyễn Thị Minh, Huyền and Nikolaev, Vitaly and Nurmi, Hanna and Ojala, Stina and Osenova, Petya and Øvrelid, Lilja and Pascual, Elena and Passarotti, Marco and Perez, Cenel-Augusto and Perrier, Guy and Petrov, Slav and Piitulainen, Jussi and Plank, Barbara and Popel, Martin and Pretkalniņa, Lauma and Prokopidis, Prokopis and Puolakainen, Tiina and Pyysalo, Sampo and Rademaker, Alexandre and Ramasamy, Loganathan and Real, Livy and Rituma, Laura and Rosa, Rudolf and Saleh, Shadi and Sanguinetti, Manuela and Saulīte, Baiba and Schuster, Sebastian and Seddah, Djamé and Seeker, Wolfgang and Seraji, Mojgan and Shakurova, Lena and Shen, Mo and Sichinava, Dmitry and Silveira, Natalia and Simi, Maria and Simionescu, Radu and Simkó, Katalin and Šimková, Mária and Simov, Kiril and Smith, Aaron and Suhr, Alane and Sulubacak, Umut and Szántó, Zsolt and Taji, Dima and Tanaka, Takaaki and Tsarfaty, Reut and Tyers, Francis and Uematsu, Sumire and Uria, Larraitz and van Noord, Gertjan and Varga, Viktor and Vincze, Veronika and Washington, Jonathan North and Žabokrtský, Zdeněk and Zeldes, Amir and Zeman, Daniel and Zhu, Hanzhi},
	month = mar,
	year = {2017},
	note = {Accepted: 2017-03-14T13:16:19Z
Publisher: Universal Dependencies Consortium},
}

@misc{noauthor_ud_german-gsd_nodate,
	title = {{UD}\_German-{GSD}},
	url = {https://universaldependencies.org/treebanks/de_gsd/index.html},
	urldate = {2023-07-06},
	file = {UD_German-GSD:C\:\\Users\\jobsc\\Zotero\\storage\\5IWC7EBH\\index.html:text/html},
}

@book{wild_learning_2016,
	address = {Cham},
	title = {Learning {Analytics} in {R} with {SNA}, {LSA}, and {MPIA}},
	isbn = {978-3-319-28789-8 978-3-319-28791-1},
	url = {http://link.springer.com/10.1007/978-3-319-28791-1},
	language = {en},
	urldate = {2023-07-06},
	publisher = {Springer International Publishing},
	author = {Wild, Fridolin},
	year = {2016},
	doi = {10.1007/978-3-319-28791-1},
	keywords = {Learning, Latent Semantic Analysis, Learning Analytics, Linear Algebra, Social Network Analysis},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\CEZC7HLL\\Wild - 2016 - Learning Analytics in R with SNA, LSA, and MPIA.pdf:application/pdf},
}

@inproceedings{evert_zipfr_2007,
	title = {{zipfR}: {Word} frequency distributions in {R}},
	shorttitle = {{zipfR}},
	booktitle = {Proceedings of the 45th annual meeting of the {ACL} on interactive poster and demonstration sessions},
	author = {Evert, Stefan and Baroni, Marco},
	year = {2007},
	pages = {29--32},
}

@article{silge_tidytext_2016,
	title = {tidytext: {Text} {Mining} and {Analysis} {Using} {Tidy} {Data} {Principles} in {R}},
	volume = {1},
	url = {http://dx.doi.org/10.21105/joss.00037},
	doi = {10.21105/joss.00037},
	number = {3},
	journal = {JOSS},
	author = {Silge, Julia and Robinson, David},
	year = {2016},
	note = {Publisher: The Open Journal},
}

@inproceedings{evert_simple_2004,
	title = {A simple {LNRE} model for random character sequences},
	volume = {2004},
	booktitle = {Proceedings of {JADT}},
	author = {Evert, Stefan},
	year = {2004},
	pages = {411--422},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\2DIWWT2Z\\Evert - 2004 - A simple LNRE model for random character sequences.pdf:application/pdf},
}

@article{kyle_measuring_2019,
	title = {Measuring lexical richness},
	journal = {The Routledge handbook of vocabulary studies},
	author = {Kyle, Kristopher},
	year = {2019},
	note = {Publisher: Routledge},
	pages = {454--475},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\7BLN5W59\\books.html:text/html},
}

@article{tweedie_how_1998,
	title = {How variable may a constant be? {Measures} of lexical richness in perspective},
	volume = {32},
	shorttitle = {How variable may a constant be?},
	journal = {Computers and the Humanities},
	author = {Tweedie, Fiona J. and Baayen, R. Harald},
	year = {1998},
	note = {Publisher: Springer},
	pages = {323--352},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\RWMJL7LB\\TWEEDIE and BAAYEN - 1998 - How Variable May a Constant be Measures of Lexica.pdf:application/pdf},
}

@misc{vanmassenhove_machine_2021,
	title = {Machine {Translationese}: {Effects} of {Algorithmic} {Bias} on {Linguistic} {Complexity} in {Machine} {Translation}},
	shorttitle = {Machine {Translationese}},
	url = {http://arxiv.org/abs/2102.00287},
	doi = {10.48550/arXiv.2102.00287},
	abstract = {Recent studies in the field of Machine Translation (MT) and Natural Language Processing (NLP) have shown that existing models amplify biases observed in the training data. The amplification of biases in language technology has mainly been examined with respect to specific phenomena, such as gender bias. In this work, we go beyond the study of gender in MT and investigate how bias amplification might affect language in a broader sense. We hypothesize that the 'algorithmic bias', i.e. an exacerbation of frequently observed patterns in combination with a loss of less frequent ones, not only exacerbates societal biases present in current datasets but could also lead to an artificially impoverished language: 'machine translationese'. We assess the linguistic richness (on a lexical and morphological level) of translations created by different data-driven MT paradigms - phrase-based statistical (PB-SMT) and neural MT (NMT). Our experiments show that there is a loss of lexical and morphological richness in the translations produced by all investigated MT paradigms for two language pairs (EN{\textless}={\textgreater}FR and EN{\textless}={\textgreater}ES).},
	urldate = {2023-07-12},
	publisher = {arXiv},
	author = {Vanmassenhove, Eva and Shterionov, Dimitar and Gwilliam, Matthew},
	month = jan,
	year = {2021},
	note = {arXiv:2102.00287 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\ICYQ3YDX\\Vanmassenhove et al. - 2021 - Machine Translationese Effects of Algorithmic Bia.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\BJ5L53Z5\\2102.html:text/html},
}

@incollection{baayen_quantitative_1992,
	address = {Dordrecht},
	series = {Yearbook of {Morphology}},
	title = {Quantitative aspects of morphological productivity},
	isbn = {978-94-011-2516-1},
	url = {https://doi.org/10.1007/978-94-011-2516-1_8},
	abstract = {Research into the phenomenon of morphological productivity, “the possibility for language users to coin, unintentionally, a number of formations which are in principle uncountable” (Schultink 1961), has mainly focused on the qualitative factors which jointly determine the productivity of word formation rules. It is well known that word formation processes are subject to various syntagmatic conditions. Booij (1977) develops a typology of such conditioning factors, distinguishing between rule-specific and rule-independent restrictions on the one hand, and between restrictions pertaining to phonological, stratal and syntactic characteristics on the other.1 The rôle of pardigmatic factors is discussed in van Marie (1985). He points out that (roughly) synonymous affixes tend to select their base words from complementary domains. Hence they can be analyzed as mutually affecting their respective degrees of productivity.},
	language = {en},
	urldate = {2023-07-12},
	booktitle = {Yearbook of {Morphology} 1991},
	publisher = {Springer Netherlands},
	author = {Baayen, Harald},
	editor = {Booij, Geert and van Marle, Jaap},
	year = {1992},
	doi = {10.1007/978-94-011-2516-1_8},
	keywords = {Lexical Access, Lexical Representation, Token Frequency, Word Formation, Word Frequency},
	pages = {109--149},
}

@inproceedings{pierrehumbert_hapax_2018,
	title = {On hapax legomena and morphological productivity},
	booktitle = {Proceedings of the fifteenth workshop on computational research in phonetics, phonology, and morphology},
	author = {Pierrehumbert, Janet and Granell, Ramon},
	year = {2018},
	pages = {125--130},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\VAKHHM2S\\Pierrehumbert and Granell - 2018 - On hapax legomena and morphological productivity.pdf:application/pdf;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\BS4I8VTS\\W18-5814.html:text/html},
}

@incollection{baayen_41_2009,
	title = {41. {Corpus} linguistics in morphology: {Morphological} productivity},
	isbn = {978-3-11-021388-1},
	shorttitle = {41. {Corpus} linguistics in morphology},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110213881.2.899/html?lang=en},
	abstract = {41. Corpus linguistics in morphology: Morphological
          productivity was published in Volume 2 on page 899.},
	language = {en},
	urldate = {2023-07-12},
	booktitle = {41. {Corpus} linguistics in morphology: {Morphological}},
	publisher = {De Gruyter Mouton},
	author = {Baayen, R. Harald},
	month = mar,
	year = {2009},
	doi = {10.1515/9783110213881.2.899},
	pages = {899--919},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\H6CEMVRU\\Baayen - 2009 - 41. Corpus linguistics in morphology Morphologica.pdf:application/pdf},
}

@article{schroeder_childlex_2015,
	title = {{childLex}: {A} lexical database of {German} read by children},
	volume = {47},
	journal = {Behavior research methods},
	author = {Schroeder, Sascha and Würzner, Kay-Michael and Heister, Julian and Geyken, Alexander and Kliegl, Reinhold},
	year = {2015},
	note = {Publisher: Springer},
	keywords = {Child language, Lexical database, Reading development},
	pages = {1085--1094},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\Y4CP5SK6\\Schroeder et al. - 2015 - childLex a lexical database of German read by chi.pdf:application/pdf},
}

@article{schroter_developmental_2017,
	title = {The {Developmental} {Lexicon} {Project}: {A} behavioral database to investigate visual word recognition across the lifespan},
	volume = {49},
	journal = {Behavior Research Methods},
	author = {Schröter, Pauline and Schroeder, Sascha},
	year = {2017},
	note = {Publisher: Springer},
	pages = {2183--2203},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\JPC9E5CE\\s13428-016-0851-9.html:text/html},
}

@article{yarkoni_moving_2008,
	title = {Moving beyond {Coltheart}’s {N}: {A} new measure of orthographic similarity},
	volume = {15},
	number = {5},
	journal = {Psychonomic bulletin \& review},
	author = {Yarkoni, Tal and Balota, David and Yap, Melvin},
	year = {2008},
	note = {Publisher: Springer},
	pages = {971--979},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\7PAT84NK\\r855u1v1mr980v32.html:text/html},
}

@article{akaike_new_1974,
	title = {A new look at the statistical model identification},
	volume = {19},
	doi = {10.1109/TAC.1974.1100705},
	number = {6},
	journal = {IEEE Transactions on Automatic Control},
	author = {Akaike, H.},
	year = {1974},
	pages = {716--723},
}

@article{brysbaert_word_2011,
	title = {The {Word} {Frequency} {Effect}},
	volume = {58},
	url = {https://doi.org/10.1027\%2F1618-3169\%2Fa000123},
	doi = {10.1027/1618-3169/a000123},
	number = {5},
	journal = {Experimental Psychology},
	author = {Brysbaert, Marc and Buchmeier, Matthias and Conrad, Markus and Jacobs, Arthur M. and Bölte, Jens and Böhl, Andrea},
	month = jul,
	year = {2011},
	note = {Publisher: Hogrefe Publishing Group},
	keywords = {word recognition, lexical decision, megastudy, word frequency},
	pages = {412--424},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\RPDXHDDQ\\Brysbaert et al. - 2011 - The Word Frequency Effect.pdf:application/pdf},
}

@article{heister_dlexdb_2011,
	title = {{dlexDB} – eine lexikalische {Datenbank} für die psychologische und linguistische {Forschung}},
	volume = {62},
	url = {https://doi.org/10.1026/0033-3042/a000029},
	doi = {10.1026/0033-3042/a000029},
	abstract = {Zusammenfassung. Mit der lexikalischen Datenbank dlexDB stellen wir der psychologischen und linguistischen Forschung im World Wide Web online statistische Kennwerte für eine Vielzahl von verarbeitungsrelevanten Merkmalen von Wörtern zur Verfügung. Diese Kennwerte umfassen die durch CELEX (Baayen, Piepenbrock und Gulikers, 1995) bekannten Variablen der Häufigkeiten von Wortformen und Lemmata in Texten geschriebener Sprache. Darüber hinaus berechnen wir eine Reihe neuer Kennwerte wie die Häufigkeiten von Silben, Morphemen, Zeichenfolgen und Mehrwortverbindungen sowie Wortähnlichkeitsmaße. Die Datengrundlage bildet das Kernkorpus des Digitalen Wörterbuchs der deutschen Sprache (DWDS) mit über 100 Millionen laufenden Wörtern. Wir illustrieren die Validität dieser Kennwerte mit neuen Ergebnissen zu ihrem Einfluss auf Fixationsdauern beim Lesen von Sätzen.},
	number = {1},
	journal = {Psychologische Rundschau},
	author = {Heister, Julian and Würzner, Kay-Michael and Bubenzer, Johannes and Pohl, Edmund and Hanneforth, Thomas and Geyken, Alexander and Kliegl, Reinhold},
	year = {2011},
	note = {\_eprint: https://doi.org/10.1026/0033-3042/a000029},
	pages = {10--20},
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models}, {Using} lme4},
	volume = {67},
	url = {https://doi.org/10.18637\%2Fjss.v067.i01},
	doi = {10.18637/jss.v067.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	note = {Publisher: Foundation for Open Access Statistic},
	keywords = {Statistics - Computation},
	file = {arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\RRP9C9MR\\1406.html:text/html;Bates et al_2014_Fitting linear mixed-effects models using lme4.pdf:C\:\\Users\\jobsc\\Zotero\\storage\\34C89HP4\\Bates et al_2014_Fitting linear mixed-effects models using lme4.pdf:application/pdf},
}

@article{gagl_lexical_2022,
	title = {The lexical categorization model: {A} computational model of left ventral occipito-temporal cortex activation in visual word recognition},
	volume = {18},
	shorttitle = {The lexical categorization model},
	number = {6},
	journal = {Plos Computational Biology},
	author = {Gagl, Benjamin and Richlan, Fabio and Ludersdorfer, Philipp and Sassenhagen, Jona and Eisenhauer, Susanne and Gregorova, Klara and Fiebach, Christian J.},
	year = {2022},
	note = {Publisher: Public Library of Science San Francisco, CA USA},
	pages = {e1009995},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\VVQMRECY\\article.html:text/html},
}

@article{dehaene_unique_2011,
	title = {The unique role of the visual word form area in reading},
	volume = {15},
	number = {6},
	journal = {Trends in cognitive sciences},
	author = {Dehaene, Stanislas and Cohen, Laurent},
	year = {2011},
	note = {Publisher: Elsevier},
	pages = {254--262},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\RPLKBWIJ\\S1364661311000738.html:text/html;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\I6TRKNH5\\S1364-6613(11)00073-8.html:text/html},
}

@book{baayen_word_2001,
	title = {Word frequency distributions},
	volume = {18},
	publisher = {Springer Science \& Business Media},
	author = {Baayen, R. Harald},
	year = {2001},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\9TZIILMK\\books.html:text/html},
}

@article{min_recent_2021,
	title = {Recent advances in natural language processing via large pre-trained language models: {A} survey},
	shorttitle = {Recent advances in natural language processing via large pre-trained language models},
	journal = {ACM Computing Surveys},
	author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
	year = {2021},
	note = {Publisher: ACM New York, NY},
}

@article{singhal_large_2023,
	title = {Large language models encode clinical knowledge},
	volume = {620},
	copyright = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06291-2},
	doi = {10.1038/s41586-023-06291-2},
	abstract = {Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6\% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17\%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.},
	language = {en},
	number = {7972},
	urldate = {2023-09-06},
	journal = {Nature},
	author = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S. Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly, Chris and Babiker, Abubakr and Schärli, Nathanael and Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman, Dina and Agüera y Arcas, Blaise and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Chou, Katherine and Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar, Alvin and Barral, Joelle and Semturs, Christopher and Karthikesalingam, Alan and Natarajan, Vivek},
	month = aug,
	year = {2023},
	note = {Number: 7972
Publisher: Nature Publishing Group},
	keywords = {Medical research, Health care},
	pages = {172--180},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\KQWEMSAZ\\Singhal et al. - 2023 - Large language models encode clinical knowledge.pdf:application/pdf},
}

@article{kasneci_chatgpt_2023,
	title = {{ChatGPT} for good? {On} opportunities and challenges of large language models for education},
	volume = {103},
	issn = {1041-6080},
	shorttitle = {{ChatGPT} for good?},
	url = {https://www.sciencedirect.com/science/article/pii/S1041608023000195},
	doi = {10.1016/j.lindif.2023.102274},
	abstract = {Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.},
	urldate = {2023-09-06},
	journal = {Learning and Individual Differences},
	author = {Kasneci, Enkelejda and Sessler, Kathrin and Küchemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and Günnemann, Stephan and Hüllermeier, Eyke and Krusche, Stephan and Kutyniok, Gitta and Michaeli, Tilman and Nerdel, Claudia and Pfeffer, Jürgen and Poquet, Oleksandra and Sailer, Michael and Schmidt, Albrecht and Seidel, Tina and Stadler, Matthias and Weller, Jochen and Kuhn, Jochen and Kasneci, Gjergji},
	month = apr,
	year = {2023},
	keywords = {Education, Artificial intelligence, Large language models, Educational technologies},
	pages = {102274},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\3YBHVQLN\\Kasneci et al. - 2023 - ChatGPT for good On opportunities and challenges .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\IFIAGXUD\\S1041608023000195.html:text/html;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\SNL3K4DE\\S1041608023000195.html:text/html},
}

@inproceedings{chandra_synthetic_2023,
	address = {New York, NY, USA},
	series = {{ETRA} '23},
	title = {Synthetic predictabilities from large language models explain reading eye movements},
	isbn = {9798400701504},
	url = {https://dl.acm.org/doi/10.1145/3588015.3588420},
	doi = {10.1145/3588015.3588420},
	abstract = {A long tradition in eye movement research has focused on three linguistic variables explaining fixation durations during sentence reading: word length, frequency, and predictability. Lengths and frequencies are easily obtainable but predictabilities are tedious to collect, requiring the incremental cloze procedure. Modern large language models are trained using the objective of predicting the next word given previous context, hence they readily provide predictability information. This capability has largely been overlooked in eye movement research. Here we investigate the suitability of a synthetic predictability measure, extracted from pretrained GPT-2 models, as a surrogate for cloze predictability. Using several published eye movement corpora, we find that synthetic and cloze predictabilities are highly correlated, and that their influence on eye movements is qualitatively similar. Similar patterns are obtained when including synthetic predictabilities in data sets lacking cloze predictabilities. In conclusion, synthetic predictabilities can serve as a substitute for empirical cloze predictabilities.},
	urldate = {2023-09-06},
	booktitle = {Proceedings of the 2023 {Symposium} on {Eye} {Tracking} {Research} and {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Chandra, Johan and Witzig, Nicholas and Laubrock, Jochen},
	month = may,
	year = {2023},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\JRHV4IN2\\Chandra et al. - 2023 - Synthetic predictabilities from large language mod.pdf:application/pdf},
}

@article{heilbron_prediction_2021,
	title = {Prediction and preview strongly affect reading times but not skipping during natural reading},
	journal = {BioRxiv},
	author = {Heilbron, Micha and van Haren, Jorie and Hagoort, Peter and de Lange, Floris P.},
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {2021--10},
}

@misc{heilbron_prediction_2022,
	title = {Prediction and preview strongly affect reading times but not skipping during natural reading},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.06.463362v2},
	doi = {10.1101/2021.10.06.463362},
	abstract = {In a typical text, readers look much longer at some words than at others and fixate some words multiple times, while skipping others altogether. Historically, researchers explained this variation via low-level visual or oculomotor factors, but today it is primarily explained in terms of cognitive factors, such as how well word identity can be predicted from context or discerned from parafoveal preview. While the existence of these effects has been well established in experiments, the relative importance of prediction, preview and low-level factors for eye movement variation in natural reading is unclear. Here, we address this question in three large datasets (n=104, 1.5 million words), using a deep neural network and Bayesian ideal observer to model linguistic prediction and parafoveal preview from moment to moment in natural reading. Strikingly, neither prediction nor preview was important for explaining word skipping – the vast majority of skipping was explained by a simple oculomotor model. For reading times, by contrast, we found strong but independent contributions of both prediction and preview, with effect sizes matching those from controlled experiments. Together, these results challenge dominant models of eye movements in reading by showing that linguistic prediction and parafoveal preview are not important determinants of word skipping.},
	language = {en},
	urldate = {2023-09-06},
	publisher = {bioRxiv},
	author = {Heilbron, Micha and Haren, Jorie van and Hagoort, Peter and Lange, Floris P. de},
	month = feb,
	year = {2022},
	note = {Pages: 2021.10.06.463362
Section: New Results},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\GHLPY7L4\\Heilbron et al. - 2022 - Prediction and preview strongly affect reading tim.pdf:application/pdf},
}

@misc{noauthor_openai_nodate,
	title = {{OpenAI}},
	url = {https://openai.com/},
	abstract = {Creating safe AGI that benefits all of humanity},
	language = {en-US},
	urldate = {2023-09-06},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\9N8UXMEX\\openai.com.html:text/html},
}

@inproceedings{liesenfeld_opening_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {Opening up {ChatGPT}: {Tracking} openness, transparency, and accountability in instruction-tuned text generators},
	isbn = {9798400700149},
	shorttitle = {Opening up {ChatGPT}},
	url = {https://dl.acm.org/doi/10.1145/3571884.3604316},
	doi = {10.1145/3571884.3604316},
	abstract = {Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.},
	urldate = {2023-09-06},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
	month = jul,
	year = {2023},
	keywords = {chatGPT, large language models, open source, RLHF, survey},
	pages = {1--6},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\CCD5NFLC\\Liesenfeld et al. - 2023 - Opening up ChatGPT Tracking openness, transparenc.pdf:application/pdf},
}

@book{schnell_understanding_2021,
	address = {London},
	title = {Understanding {Corpus} {Linguistics}},
	isbn = {978-0-429-26903-5},
	abstract = {This textbook introduces the fundamental concepts and methods of corpus linguistics for students approaching this topic for the first time, putting specific emphasis on the enormous linguistic diversity represented by approximately  7,000 human languages and broadening the scope of current concerns in general corpus linguistics.
Including a basic toolkit to help the reader investigate language in different usage contexts, this book:

Shows the relevance of corpora to a range of linguistic areas from phonology to sociolinguistics and discourse
Covers recent developments in the application of corpus linguistics to the study of understudied languages and linguistic typology
Features exercises, short problems, and questions
Includes examples from real studies in over 15 languages plus multilingual corpora
Providing the necessary corpus linguistics skills to critically evaluate and replicate studies, this book is essential reading for anyone studying corpus linguistics.},
	publisher = {Routledge},
	author = {Schnell, Stefan, Danielle Barth},
	month = nov,
	year = {2021},
	doi = {10.4324/9780429269035},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\T8AT6PKM\\Schnell - 2021 - Understanding Corpus Linguistics.pdf:application/pdf},
}

@misc{noauthor_custom_nodate,
	title = {Custom instructions for {ChatGPT}},
	url = {https://openai.com/blog/custom-instructions-for-chatgpt},
	abstract = {We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.},
	language = {en-US},
	urldate = {2023-09-06},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\ZLZNJLEA\\custom-instructions-for-chatgpt.html:text/html},
}

@article{cain_matthew_2011,
	title = {Matthew effects in young readers: {Reading} comprehension and reading experience aid vocabulary development},
	volume = {44},
	shorttitle = {Matthew effects in young readers},
	number = {5},
	journal = {Journal of learning disabilities},
	author = {Cain, Kate and Oakhill, Jane},
	year = {2011},
	note = {Publisher: Sage Publications Sage CA: Los Angeles, CA},
	pages = {431--443},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\5FBHB2GP\\0022219411410042.html:text/html},
}

@article{cunningham_vocabulary_2005,
	title = {Vocabulary growth through independent reading and reading aloud to children},
	journal = {Teaching and learning vocabulary: Bringing research to practice},
	author = {Cunningham, Anne E.},
	year = {2005},
	pages = {45--68},
	file = {Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\J239K4MI\\books.html:text/html},
}

@article{segbers_how_2017,
	title = {How many words do children know? {A} corpus-based estimation of children’s total vocabulary size},
	volume = {34},
	shorttitle = {How many words do children know?},
	number = {3},
	journal = {Language Testing},
	author = {Segbers, Jutta and Schroeder, Sascha},
	year = {2017},
	note = {Publisher: Sage Publications Sage UK: London, England},
	pages = {297--320},
}

@article{elhaik_principal_2022,
	title = {Principal {Component} {Analyses} ({PCA})-based findings in population genetic studies are highly biased and must be reevaluated},
	volume = {12},
	issn = {2045-2322},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9424212/},
	doi = {10.1038/s41598-022-14395-4},
	abstract = {Principal Component Analysis (PCA) is a multivariate analysis that reduces the complexity of datasets while preserving data covariance. The outcome can be visualized on colorful scatterplots, ideally with only a minimal loss of information. PCA applications, implemented in well-cited packages like EIGENSOFT and PLINK, are extensively used as the foremost analyses in population genetics and related fields (e.g., animal and plant or medical genetics). PCA outcomes are used to shape study design, identify, and characterize individuals and populations, and draw historical and ethnobiological conclusions on origins, evolution, dispersion, and relatedness. The replicability crisis in science has prompted us to evaluate whether PCA results are reliable, robust, and replicable. We analyzed twelve common test cases using an intuitive color-based model alongside human population data. We demonstrate that PCA results can be artifacts of the data and can be easily manipulated to generate desired outcomes. PCA adjustment also yielded unfavorable outcomes in association studies. PCA results may not be reliable, robust, or replicable as the field assumes. Our findings raise concerns about the validity of results reported in the population genetics literature and related fields that place a disproportionate reliance upon PCA outcomes and the insights derived from them. We conclude that PCA may have a biasing role in genetic investigations and that 32,000-216,000 genetic studies should be reevaluated. An alternative mixed-admixture population genetic model is discussed.},
	urldate = {2023-09-07},
	journal = {Scientific Reports},
	author = {Elhaik, Eran},
	month = aug,
	year = {2022},
	pmid = {36038559},
	pmcid = {PMC9424212},
	pages = {14683},
	file = {PubMed Central Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\IYV767W2\\Elhaik - 2022 - Principal Component Analyses (PCA)-based findings .pdf:application/pdf},
}

@article{shatz_potential_2023,
	title = {The potential influence of crosslinguistic lexical similarity on lexical diversity in {L2} {English} writing},
	journal = {Corpora},
	author = {Shatz, Itamar and Alexopoulou, Theodora and Murakami, Akira},
	year = {2023},
	note = {Publisher: Edinburgh University Press},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\578P74QS\\Shatz et al. - 2023 - The potential influence of crosslinguistic lexical.pdf:application/pdf;Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\QJQ8GG2E\\the-potential-influence-of-crosslinguistic-lexical-similarity-on-.html:text/html},
}

@article{rouder_lognormal_2015,
	title = {The {Lognormal} {Race}: {A} {Cognitive}-{Process} {Model} of {Choice} and {Latency} with {Desirable} {Psychometric} {Properties}},
	volume = {80},
	issn = {1860-0980},
	shorttitle = {The {Lognormal} {Race}},
	url = {https://doi.org/10.1007/s11336-013-9396-3},
	doi = {10.1007/s11336-013-9396-3},
	abstract = {We present a cognitive process model of response choice and response time performance data that has excellent psychometric properties and may be used in a wide variety of contexts. In the model there is an accumulator associated with each response option. These accumulators have bounds, and the first accumulator to reach its bound determines the response time and response choice. The times at which accumulator reaches its bound is assumed to be lognormally distributed, hence the model is race or minima process among lognormal variables. A key property of the model is that it is relatively straightforward to place a wide variety of models on the logarithm of these finishing times including linear models, structural equation models, autoregressive models, growth-curve models, etc. Consequently, the model has excellent statistical and psychometric properties and can be used in a wide range of contexts, from laboratory experiments to high-stakes testing, to assess performance. We provide a Bayesian hierarchical analysis of the model, and illustrate its flexibility with an application in testing and one in lexical decision making, a reading skill.},
	language = {en},
	number = {2},
	urldate = {2023-09-15},
	journal = {Psychometrika},
	author = {Rouder, Jeffrey N. and Province, Jordan M. and Morey, Richard D. and Gomez, Pablo and Heathcote, Andrew},
	month = jun,
	year = {2015},
	keywords = {cognitive psychometrics, race models, response-times models},
	pages = {491--513},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\EBBWVWI2\\Rouder et al. - 2015 - The Lognormal Race A Cognitive-Process Model of C.pdf:application/pdf},
}

@article{laarmann-quante_litkey_2019,
	title = {The {Litkey} {Corpus}: {A} richly annotated longitudinal corpus of {German} texts written by primary school children},
	volume = {51},
	issn = {1554-3528},
	shorttitle = {The {Litkey} {Corpus}},
	url = {http://link.springer.com/10.3758/s13428-019-01261-x},
	doi = {10.3758/s13428-019-01261-x},
	language = {en},
	number = {4},
	urldate = {2023-09-19},
	journal = {Behavior Research Methods},
	author = {Laarmann-Quante, Ronja and Ortmann, Katrin and Ehlert, Anna and Masloch, Simon and Scholz, Doreen and Belke, Eva and Dipper, Stefanie},
	month = aug,
	year = {2019},
	pages = {1889--1918},
	file = {Full Text:C\:\\Users\\jobsc\\Zotero\\storage\\R2G3I9YN\\Laarmann-Quante et al. - 2019 - The Litkey Corpus A richly annotated longitudinal.pdf:application/pdf},
}

@misc{sawicki_bits_2023,
	title = {Bits of {Grass}: {Does} {GPT} already know how to write like {Whitman}?},
	shorttitle = {Bits of {Grass}},
	url = {http://arxiv.org/abs/2305.11064},
	doi = {10.48550/arXiv.2305.11064},
	abstract = {This study examines the ability of GPT-3.5, GPT-3.5-turbo (ChatGPT) and GPT-4 models to generate poems in the style of specific authors using zero-shot and many-shot prompts (which use the maximum context length of 8192 tokens). We assess the performance of models that are not fine-tuned for generating poetry in the style of specific authors, via automated evaluation. Our findings indicate that without fine-tuning, even when provided with the maximum number of 17 poem examples (8192 tokens) in the prompt, these models do not generate poetry in the desired style.},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Sawicki, Piotr and Grzes, Marek and Goes, Fabricio and Brown, Dan and Peeperkorn, Max and Khatun, Aisha},
	month = may,
	year = {2023},
	note = {arXiv:2305.11064 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\QFUT4YX2\\Sawicki et al. - 2023 - Bits of Grass Does GPT already know how to write .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\G87A2LSC\\2305.html:text/html},
}

@misc{kumarage_neural_2023,
	title = {Neural {Authorship} {Attribution}: {Stylometric} {Analysis} on {Large} {Language} {Models}},
	shorttitle = {Neural {Authorship} {Attribution}},
	url = {http://arxiv.org/abs/2308.07305},
	doi = {10.48550/arXiv.2308.07305},
	abstract = {Large language models (LLMs) such as GPT-4, PaLM, and Llama have significantly propelled the generation of AI-crafted text. With rising concerns about their potential misuse, there is a pressing need for AI-generated-text forensics. Neural authorship attribution is a forensic effort, seeking to trace AI-generated text back to its originating LLM. The LLM landscape can be divided into two primary categories: proprietary and open-source. In this work, we delve into these emerging categories of LLMs, focusing on the nuances of neural authorship attribution. To enrich our understanding, we carry out an empirical analysis of LLM writing signatures, highlighting the contrasts between proprietary and open-source models, and scrutinizing variations within each group. By integrating stylometric features across lexical, syntactic, and structural aspects of language, we explore their potential to yield interpretable results and augment pre-trained language model-based classifiers utilized in neural authorship attribution. Our findings, based on a range of state-of-the-art LLMs, provide empirical insights into neural authorship attribution, paving the way for future investigations aimed at mitigating the threats posed by AI-generated misinformation.},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Kumarage, Tharindu and Liu, Huan},
	month = aug,
	year = {2023},
	note = {arXiv:2308.07305 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\BQJFMFRI\\Kumarage and Liu - 2023 - Neural Authorship Attribution Stylometric Analysi.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\SJD68H74\\2308.html:text/html},
}

@article{marinus_variability_2010,
	title = {Variability in the word-reading performance of dyslexic readers: {Effects} of letter length, phoneme length and digraph presence},
	volume = {46},
	number = {10},
	journal = {Cortex},
	author = {Marinus, Eva and de Jong, Peter F},
	year = {2010},
	note = {Publisher: Elsevier},
	pages = {1259--1271},
}

@article{huestegge_oculomotor_2009,
	title = {Oculomotor and linguistic determinants of reading development: {A} longitudinal study},
	volume = {49},
	number = {24},
	journal = {Vision research},
	author = {Huestegge, Lynn and Radach, Ralph and Corbic, Daniel and Huestegge, Sujata M},
	year = {2009},
	note = {Publisher: Elsevier},
	pages = {2948--2959},
}

@article{gagl_sources_2015,
	title = {On sources of the word length effect in young readers},
	volume = {19},
	number = {4},
	journal = {Scientific Studies of Reading},
	author = {Gagl, Benjamin and Hawelka, Stefan and Wimmer, Heinz},
	year = {2015},
	note = {Publisher: Taylor \& Francis},
	pages = {289--306},
}

@article{weekes_effects_2006,
	title = {Effects of consistency and age of acquisition on reading and spelling among developing readers},
	volume = {19},
	journal = {Reading and Writing},
	author = {Weekes, Brendan S and Castles, Anne E and Davies, Robert A},
	year = {2006},
	note = {Publisher: Springer},
	pages = {133--169},
}

@article{hawelka_beyond_2013,
	title = {Beyond single syllables: the effect of first syllable frequency and orthographic similarity on eye movements during silent reading},
	volume = {28},
	number = {8},
	journal = {Language and Cognitive processes},
	author = {Hawelka, Stefan and Schuster, Sarah and Gagl, Benjamin and Hutzler, Florian},
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	pages = {1134--1153},
}

@inproceedings{mcdonald_universal_2013,
	title = {Universal dependency annotation for multilingual parsing},
	booktitle = {Proceedings of the 51st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	author = {McDonald, Ryan and Nivre, Joakim and Quirmbach-Brundage, Yvonne and Goldberg, Yoav and Das, Dipanjan and Ganchev, Kuzman and Hall, Keith and Petrov, Slav and Zhang, Hao and Täckström, Oscar and {others}},
	year = {2013},
	pages = {92--97},
}

@article{zoccolotti_word_2005,
	title = {Word length effect in early reading and in developmental dyslexia},
	volume = {93},
	number = {3},
	journal = {Brain and language},
	author = {Zoccolotti, Pierluigi and De Luca, Maria and Di Pace, Enrico and Gasperini, Filippo and Judica, Anna and Spinelli, Donatella},
	year = {2005},
	note = {Publisher: Elsevier},
	pages = {369--373},
}

@article{blasi_over-reliance_2022,
	title = {Over-reliance on {English} hinders cognitive science},
	volume = {26},
	number = {12},
	journal = {Trends in cognitive sciences},
	author = {Blasi, Damián E and Henrich, Joseph and Adamou, Evangelia and Kemmerer, David and Majid, Asifa},
	year = {2022},
	note = {Publisher: Elsevier},
	pages = {1153--1170},
}

@article{gagl_eye_2022,
	title = {Eye movements during text reading align with the rate of speech production},
	volume = {6},
	number = {3},
	journal = {Nature human behaviour},
	author = {Gagl, Benjamin and Gregorova, Klara and Golch, Julius and Hawelka, Stefan and Sassenhagen, Jona and Tavano, Alessandro and Poeppel, David and Fiebach, Christian J},
	year = {2022},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {429--442},
}

@article{gagl_investigating_2023,
	title = {Investigating lexical categorization in visual word recognition based on a joint diagnostic and training approach for language learners.},
	author = {Gagl, Benjamin and Gregorova, Klara},
	year = {2023},
	note = {Publisher: PsyArXiv},
}

@article{staub_effect_2015,
	title = {The effect of lexical predictability on eye movements in reading: {Critical} review and theoretical interpretation},
	volume = {9},
	number = {8},
	journal = {Language and Linguistics Compass},
	author = {Staub, Adrian},
	year = {2015},
	note = {Publisher: Wiley Online Library},
	pages = {311--327},
}

@article{hawelka_forward_2015,
	title = {On forward inferences of fast and slow readers. {An} eye movement study},
	volume = {5},
	number = {1},
	journal = {Scientific reports},
	author = {Hawelka, Stefan and Schuster, Sarah and Gagl, Benjamin and Hutzler, Florian},
	year = {2015},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {8432},
}

@article{hawelka_dual-route_2010,
	title = {A dual-route perspective on eye movements of dyslexic readers},
	volume = {115},
	number = {3},
	journal = {Cognition},
	author = {Hawelka, Stefan and Gagl, Benjamin and Wimmer, Heinz},
	year = {2010},
	note = {Publisher: Elsevier},
	pages = {367--379},
}

@article{kliegl_length_2004,
	title = {Length, frequency, and predictability effects of words on eye movements in reading},
	volume = {16},
	number = {1-2},
	journal = {European journal of cognitive psychology},
	author = {Kliegl, Reinhold and Grabner, Ellen and Rolfs, Martin and Engbert, Ralf},
	year = {2004},
	note = {Publisher: Taylor \& Francis},
	pages = {262--284},
}

@misc{ziems_can_2023,
	title = {Can {Large} {Language} {Models} {Transform} {Computational} {Social} {Science}?},
	url = {http://arxiv.org/abs/2305.03514},
	doi = {10.48550/arXiv.2305.03514},
	abstract = {Large Language Models (LLMs) like ChatGPT are capable of successfully performing many language processing tasks zero-shot (without the need for training data). If this capacity also applies to the coding of social phenomena like persuasiveness and political ideology, then LLMs could effectively transform Computational Social Science (CSS). This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 24 representative CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers' gold references. We conclude that today's LLMs can radically augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the hidden meaning behind text). In summary, LLMs can significantly reduce costs and increase efficiency of social science analysis in partnership with humans.},
	urldate = {2023-10-06},
	publisher = {arXiv},
	author = {Ziems, Caleb and Held, William and Shaikh, Omar and Chen, Jiaao and Zhang, Zhehao and Yang, Diyi},
	month = apr,
	year = {2023},
	note = {arXiv:2305.03514 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\jobsc\\Zotero\\storage\\LE392F2E\\Ziems et al. - 2023 - Can Large Language Models Transform Computational .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jobsc\\Zotero\\storage\\D3WADM8E\\2305.html:text/html},
}

@article{piantadosi_zipfs_2014,
	title = {Zipf’s word frequency law in natural language: {A} critical review and future directions},
	volume = {21},
	issn = {1531-5320},
	shorttitle = {Zipf’s word frequency law in natural language},
	url = {https://doi.org/10.3758/s13423-014-0585-6},
	doi = {10.3758/s13423-014-0585-6},
	abstract = {The frequency distribution of words has been a key object of study in statistical linguistics for the past 70 years. This distribution approximately follows a simple mathematical form known as Zipf’s law. This article first shows that human language has a highly complex, reliable structure in the frequency distribution over and above this classic law, although prior data visualization methods have obscured this fact. A number of empirical phenomena related to word frequencies are then reviewed. These facts are chosen to be informative about the mechanisms giving rise to Zipf’s law and are then used to evaluate many of the theoretical explanations of Zipf’s law in language. No prior account straightforwardly explains all the basic facts or is supported with independent evaluation of its underlying assumptions. To make progress at understanding why language obeys Zipf’s law, studies must seek evidence beyond the law itself, testing assumptions and evaluating novel predictions with new, independent data.},
	language = {en},
	number = {5},
	urldate = {2023-10-12},
	journal = {Psychonomic Bulletin \& Review},
	author = {Piantadosi, Steven T.},
	month = oct,
	year = {2014},
	keywords = {Statistics, Language, Zipf’s law},
	pages = {1112--1130},
	file = {Full Text PDF:C\:\\Users\\jobsc\\Zotero\\storage\\FCFN7PJW\\Piantadosi - 2014 - Zipf’s word frequency law in natural language A c.pdf:application/pdf},
}

@incollection{yli-jyra_tagh_2006,
	address = {Berlin, Heidelberg},
	title = {{TAGH}: {A} {Complete} {Morphology} for {German} {Based} on {Weighted} {Finite} {State} {Automata}},
	volume = {4002},
	isbn = {978-3-540-35467-3 978-3-540-35469-7},
	shorttitle = {{TAGH}},
	url = {http://link.springer.com/10.1007/11780885_7},
	urldate = {2023-10-16},
	booktitle = {Finite-{State} {Methods} and {Natural} {Language} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Geyken, Alexander and Hanneforth, Thomas},
	editor = {Yli-Jyrä, Anssi and Karttunen, Lauri and Karhumäki, Juhani},
	year = {2006},
	doi = {10.1007/11780885_7},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {55--66},
}
